{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f66f4936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#Create and print a 3x3 array\n",
    "x=np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print('x:\\n', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11caaf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y=np.linspace(-10,10,500)\n",
    "z=np.cos(y)\n",
    "plt.plot(y,z,marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19bc4151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Segun</td>\n",
       "      <td>Ogun</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lawal</td>\n",
       "      <td>Imo</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seyi</td>\n",
       "      <td>Delta</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daniel</td>\n",
       "      <td>Kwara</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  State  Age\n",
       "0   Segun   Ogun   18\n",
       "1   Lawal    Imo   20\n",
       "2    Seyi  Delta   26\n",
       "3  Daniel  Kwara   28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Segun</td>\n",
       "      <td>Ogun</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lawal</td>\n",
       "      <td>Imo</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name State  Age\n",
       "0  Segun  Ogun   18\n",
       "1  Lawal   Imo   20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "data = {'Name':[\"Segun\", \"Lawal\", \"Seyi\", \"Daniel\"], 'State':[\"Ogun\", \"Imo\", \"Delta\", \"Kwara\"], 'Age': [18, 20, 26, 28]}\n",
    "data_pandas = pd.DataFrame(data)\n",
    "display(data_pandas)\n",
    "display(data_pandas[data_pandas.Age<=25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.list_builders()\n",
    "ds, info = tfds.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create and print a 3 x 3 array\n",
    "# Exercise 2.1 \n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"x:\\n\",format(x))\n",
    "print(\"\")\n",
    "# Create and print a 5 x 5 Identity Matrix using numpy array\n",
    "eye = np.eye(5)\n",
    "print(\"A 4x4 Identity Matrix PROF E. ADETIBA :\\n\",format(eye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e64ebbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28d61b80d30>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGdCAYAAAAfTAk2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACg5ElEQVR4nO2dd3xUZfb/P5M2KZBOSGJ6SCiCCqEkUUQNQbGtHdZd1F2Er2uJgH6/K1u+lv25rPvdpalYUeygi7i6oJJEqkkg9E5CeiAhpPc2c39/3HlunplM+pR775z365UXyZ07w70zzzzPec75nHM0giAIIAiCIAiCUBFO9r4AgiAIgiAIS0MGDkEQBEEQqoMMHIIgCIIgVAcZOARBEARBqA4ycAiCIAiCUB1k4BAEQRAEoTrIwCEIgiAIQnWQgUMQBEEQhOpwsfcF2AO9Xo9Lly5h9OjR0Gg09r4cgiAIgiAGgSAIaGpqQmhoKJyc+vfROKSBc+nSJYSHh9v7MgiCIAiCGAZlZWUICwvr9xyHNHBGjx4NQHyDvL297Xw1BEEQBEEMhsbGRoSHh0vreH84pIHDwlLe3t5k4BAEQRCEwhiMvIRExgRBEARBqA4ycAiCIAiCUB1k4BAEQRAEoTrIwCEIgiAIQnWQgUMQBEEQhOogA4cgCIIgCNVBBg5BEARBEKqDDByCIAiCIFQHGTgEQRAEQagOqxo4e/fuxV133YXQ0FBoNBp88803Az5nz549SEhIgLu7O2JiYvD222/3Omfr1q2YNGkStFotJk2ahG3btlnh6gl7sSY9D+sz880+tj4zH2vS82x8RQRBqBGaa9SNVVs1tLS04Nprr8VvfvMb3H///QOeX1RUhNtvvx1LlizBp59+ip9//hlPPvkkxowZIz0/OzsbCxYswF/+8hfce++92LZtGx566CHs378fs2bNsubtEFZkTXoeDhTVAACcNBpkFdTgy0NleGi62BQ1q6Aa5XVtKK9rQ3JsABa+m41Z0QFYnhpvz8sm7Aw/bniSYwMBiOPGFBo3BBs3bK55b18hplzlg8+XJGJ9Zj6+PFQmzTU3vPYTrvL1wJb/SrL3ZRNDRCMIgmCT/0ijwbZt23DPPff0ec7vf/97fPvttzh79qx07IknnsDx48eRnZ0NAFiwYAEaGxvx/fffS+fcdttt8PPzwxdffDGoa2lsbISPjw8aGhqoF5UMWJOeh9ziWmQV9CxU4X4eKKtr63Uufzw5NgAzovxpsXJQzI2bwUDjxrExHTf8nKJ1cUJHt77X8XA/D9w3LYzGjAwYyvotKw1OdnY25s2bZ3Ts1ltvxaFDh9DV1dXvOVlZWX2+bkdHBxobG41+CHnATzbJsQHS8bK6NjiZ9FIzNW6yCmqQW1xLbmQHpK9xMxBs3Jjz+hDqx9y4Katrw5hRWgDo07gpq2ujuUaByMrAqaysxNixY42OjR07Ft3d3aiuru73nMrKyj5fd9WqVfDx8ZF+wsPDLX/xxLBwdtJIk43pYqU38S2aGje0WDkupuMmKcZ/wOewc8XfA619iYTMMDVusgpqMD3SDwBwpbnD6FxT44ad72y66yJkjawMHKB3C3QWQeOPmzunv9bpK1euRENDg/RTVlZmwSsmRoJOL/QyWAbC9FxarBwLtotekRovGTfZhbUDPo+NlxWGMAPtxh0LU6N4eqQfDpXU9fsc3rihcaM8ZGXgBAcH9/LEVFVVwcXFBQEBAf2eY+rV4dFqtfD29jb6IeSB6aQzWGixckzYLnw1Z+QMxrhhsPGy2vA6NG4cA1OjODHGf0DjhsEbN6vT88iLoyBkZeAkJSUhPT3d6NjOnTsxffp0uLq69ntOcnKyza6TsAymk44p/TjlpOcBNOk4ErxBvDo9D5WN7UN6/pe5ZVidnkchBwfD2UljZBTnDMEoZqxOz6MNlcKwqoHT3NyMY8eO4dixYwDENPBjx46htLQUgBg6euSRR6Tzn3jiCZSUlGDFihU4e/YsPvjgA2zcuBHPP/+8dM6zzz6LnTt34rXXXsO5c+fw2muvISMjA8uWLbPmrRAWxnQnrnXpPRQHyu97f18hTToOBh/STIrxx+cHSof0/PL6Nni7u1DIwYHgN1Kr0/NQY6K34TE3DwHGxg15/5SDVQ2cQ4cOYerUqZg6dSoAYMWKFZg6dSr+93//FwBQUVEhGTsAEB0djR07dmD37t247rrr8Je//AXr1683qqGTnJyMzZs348MPP8Q111yDTZs2YcuWLVQDR2GY7sRZ9gKPt7uL2d8Zje3dCPfzAEBeHEeBHzd9haZMx4rp343t3ZKYncaN+jH13nyUXWL0OBsfLEWc/W06br46RN4/pWGzOjhygurgyIP1mfnSxGMKm0TCDAZMuSGrIczPQ/qdh+2udHqBalWolDWcMWJu3IT5eeCh6eFYnZ4Hb3cXNLZ3G+26Tc8tr2ujceMA8NlTQaO1qGrq8eCYZkkNNG7Y+StS45GWEmfT+yBEFFsHh3AMWHn0tJQ4zIzyM3pMAyAxxl/apd8/LUwyclakxiPC37PX64WRF8ch4HfiHq69py5m+K5IjcfEEG+jRYp5+vhzScPlGDCvX7ifh5FxAxhnSSXHBvQaN4km5Qd444ZaOcgfMnAIm8MWqvWZ+fD2cDV6TIDYqoEJj52dNJgVHSBNOrxXh4e0OOonLSVO0lG0dfUOabJwJwCprD4LKZTVtfWqlcNCDrQbVy+8/oavjM7bs4kx4vwyI8rfaNysSI2HUx+ZDsz7TIaxvCEDh7AppoK/zLNVRo8zASg7hw8dsEnH1IvDesawc2jSUR/9NUUERC8e24XrDBUieUHyitR4mMbi2e6dduPqhW2mcgqNszRZEVHeKF7OhSv5DZWpFoeSG5QDGTiETeHDDGNGa3stOkwAOtCkY+rFKa1tpUlHxbBxk1VQjWBvbc9xww6bGbl8j6nlhl05GxPmUoP1gkC7cZUyUBkKoMd7o+PKpvMbquTYADS2dxs9h5IblAMZOIRN4cMMV0zi4StS46XJiN+JAyAvjgPDL1Q5hbWobBTHjZMG0AkCwvw8jEKaPKbjxtQwzimsJcNYpfTlvWGE+3n02kgxTL1/y+b2hDA1EL1/FN6UP2TgEDbDSFwc7dfr8ayCaskAMtft2dSLY6qp4L04NOmoB97rF+DlJh1n9i8vLtaZNjCD8bgxl4FHInV1wuaSrIIaeLg6Gz3GdFmmGykG7/1LS4kzMpLY2Ykx/hTelDm9i4sQhJXgF6pgbw8AYql0Z40GOkFATmGtZACZY3lqvBROECeuaqPHy000FZT6qw7YeDCXGr7CxENj7vM2HTeCIGBNhqjncdKI44YMY3XBSgqkpcTh5wvVOFBkHJ7UC4LkSU6MMd+Nno2l9Zn5ZsObybGBRuOKkB9k4BA2w9xCpYEYZkiODUBiTI/2pq+Fht+ND6SpoElH+fAL1b78K8gtNu4flFVQjc1LxcwXcztxBhs3aSlxWPhutnScPYXfjZNhrHz4zVRtS2fPcW4zlRwb2KfXj8HPJdkF1UbFJfnigWQYyxMycAibwC9UW3JLcbFe7CEkQIyFiw3wegv+TDHdjZtOOjmFtcgprKVJRyUYi9Lde44P0uvHoN24YzHYzVRfXj8Gv6HKLqyVCgEywvw8yDCWMaTBIWwCW6gefi9HMm4AcaFisfC+BH+mmJt0ePhJh2LjyoYXpe84WQHAeKFij/WXQs7gDRhT/dbq9DwKU6kEXut3lW+PUcxvpoC+NVs8/WVUsfDmw+/lkH5LppCBQ9gEXvDn5SYK/viF6vMliYOacACadBwFSy5UQG/DeLTBMGYjhAxjdWDJzRTQM24+X5JoZBjrhZ5xSIaxPCEDh7A6/EKVFOOPlk4dAOOFij0+WBcvTTrqx9ILlalh3GQwjAXDa5JhrA4suZkCxHHDDN/swlqM0va8JhWLlDekwSGsDl+PgtfLOGnQa6EarEHCayqyC2sR5K1FVWNHr0mHUC68jmK01gVNHd29FiqmfRgsvNj4l+9mS+NRJwhkGKuItJQ4I32egJ4GvoPRbJnCwpvsNdhrOmvEPlcPv5cjjR1CPpCBQ1gdfqHiRXp6AcNeqICeSScxxh9Bo93x7fFLRpMO02WQ+E958KL0nMIao0XF1Os3FEwNYw83Z7R16szuxmncKA++4zy/mXJ11iAxJgB6QRjyZgowycJ7Jxs5RWQYKwEycAir0tdCBYxsoQKMNRV8tgTb4WcVVEsZVYSy4L1+/JgZidePQbtx9cLGTWKMPyL9PVFS2wqNBujSCZKIPDk2cMibKWboLnxXNG78PF1R19plZBgD4nxHRrF8IAOHsCrWXKj43TjPTePHYPf5KwCoRoVS4b1+bDEBRu71A4x34w+8lYVDJWJtHdqNKx9z6eFz4nvmA/6cocKXGJgW4YfMc1VGhjEZxfKDDBzCqvATTsAoN9Q0i0W3LLFQAcZhqor6dpTUtmJP3pVe51C4QXmY8/qNREfB4A3jQyV18HRzRmunDhoN6beUzJo+xOG7z19Bcuzww1OM/jzGQE+xSEI+kIFDWB1rLVSA+UlHEMSY+zO3xFGYSoHwCxU/ZlycRqaj4OHDVNeE+eLtPQUQBOMwlbl+aIR84cNT908Lw9Yj5eJxw2c63PAUoy+PMSM5NnB4F05YDTJwCKthi4WKX4D4rIkunYCcwhqqaqxA+IXqunAfHCtrAAB060emo+Dhu0XXtfaU8ufDVH31KCLkCe8tDvMVm6ryWXeWmAN4wzinsAZ6QQy3L5sbL4XiyTCWD1QHh7AabKHKKqjGjKie7uFsoRpML5jBwrJi/DxdAQAajWhUUbhBebA6JjmFtZJxE+nv2euckSwiyw01lJJjA3C2okk6nhDpS2EqBZOWEofk2ACU14sGjml6+EjhDWM2bbF/2XGqoSQfyINDWA1zgr/AUVpUN3f0Omck8LuqWyYE4f9tP0vhBpVRUtvaKxQ50rGzPjNfMoKZh/FwSb3FwqeE7ejLWzzS9HBTWC8804QJarwpT8jAIWxKdXOHxRcqflfV3NHTtoHCDcqDLVQ6vYDlc+OwJkPcdbsYFi+mubKE10+nF5AY44/EGONwAxO+ZxVUkzhdIfBhzUmh3jhzqRHAyNPDTTFtyLo6PQ8WGIqElaAQFWEVWHsGtiAxp601Fio+3HCivAHOGvH/uCbMh8INCoMtVM5OGiNtDAtrsppKljA6lhsWPX6R0gs9ItKcwloKNygEPqzJjJsJwaN7nTPScWM6b7Hh4aTp6YlGLRvkA3lwCKvAFqoVqfFo79KBmTG8UNSSRoe5cMOJ8gYKNygMc2HNMF8PSVNhCyjcoA7OVTZZ3FvMZ1LxY5QZyPy8R9gfMnAIq2BuofL1cEV9W5dV/j8+3HCgsBY6QYCGwg2qoLy+zeILFWA+3EAoDz6s+WxKHNYZPHCuzpb3FveFi8GwAcgwlhMUoiJsRn1bF1akxmNFqphSaYmsBgYfbmCFtwQBWJchTjoUbpA/pmFNhjXCmuZej8INyoQPa17hEhiY/saSYU3A2DBePlc0ZLpJiCNLyMAhrMIaQ3o4r79hEw0gVv205o7KIMPBmox8q4TECMvDL1QtnFjcGvobQDSK01LipP/XNO2Xvx5CvjD9zer0PHx+oBQAEBXgOcCzhg9vGGs0GmmucXbSkGEsMyhERVgFZycNcgproQEk/Y1OLxg1MrS0BofCDcrGXFgzwMsNNS2dfT3FKjhTuEHxFNdYvqwAoy8dDtuwkQ5HPpCBQ1gF0/YMo7UumHyVt9WK7/G7KmcnDZw0MKoyynZVpMNRFjUtnVZbqABjw1gQBKzJGH5fNML28Pob5sUBrBfW7I/RWhcyjGUGhagIq8CymqIDRVdxc2c3sgtrLVpVlIfCDcrHHmFNCjcoG1uHNRm8YfzMLeMAAE3c/0/IA/LgEBZnTXoeDhSJYajimhYUVbdCEAA3ZyepqqitdslUZVQ52DqsCVC4QenYK6zJG8auzk7SmHUxGFTkMZYHNvHgbNiwAdHR0XB3d0dCQgL27dvX57mPPfaYYSdl/HP11VdL52zatMnsOe3t7ba4HWIA2EIFALvPXwEgfvE7dXqpB5U1vvTmshso2qAcWB8h1jDVy80ZSTH+dukp5u0hhhtIoK48WFjTGtmaDFOPMV/nCyCPsVywugdny5YtWLZsGTZs2IDrr78e77zzDubPn48zZ84gIiKi1/nr1q3D3/72N+nv7u5uXHvttXjwwQeNzvP29sb58+eNjrm7u1vnJoghYW5XtfiGaLyzt9Cq/y/bVbH/f21mvtiTykmDZw27KkK+sLBm7BgvFFxpQWunrldY0xqGBm8Yd3Tr8OauAjS2UbhBKbDv/RqDocGHNdnjtiLC35M8xjLC6gbO6tWrsXjxYjz++OMAgLVr1+LHH3/EW2+9hVWrVvU638fHBz4+PtLf33zzDerq6vCb3/zG6DyNRoPg4GDrXjxhMd7ZW2hVsSjQE25Yk56H3OJaGMrhSBMca5RHbmN5whaqy43tKLjSAgFiWJMVa7TWQmVqGG/YVdAr3EDIDyYwXp4aj3UZeb3CmtZusMsbxpcb2/HZgVKU1rZa7f8jho5VDZzOzk4cPnwYL7zwgtHxefPmISsra1CvsXHjRsydOxeRkZFGx5ubmxEZGQmdTofrrrsOf/nLXzB16lSzr9HR0YGOjp4CUI2NjUO8E2Ko6PQCbowLxN78agDiQmWrXVVucS2yCmowIWQ0zlU0wd/LDavT86SsLtJTyI81nCB05qsZAHrCmtZerHoZxobj3WQYyxoWBuKzNd1cnDAtwteo27e14A3jLp0enxlq8Lg6a/DMLWQYywGrGjjV1dXQ6XQYO3as0fGxY8eisrJywOdXVFTg+++/x+eff250fMKECdi0aROmTJmCxsZGrFu3Dtdffz2OHz+OuLjeXoFVq1bh5ZdfHtnNEIOC31XNW7MHAOCssc1CBZjvSVXX2olZ0fbRchCDgy1WWQXVqGoSNyO7nr8Jv996wiaLFdBjGEcFeKK4phUxgV5kGMsYvhRFXNAo5Fc1w9/TDTk2CGsCvQ1jRpeODGO5YBORsUZjLLQSBKHXMXNs2rQJvr6+uOeee4yOJyYm4te//jWuvfZazJ49G19++SXi4+Px+uuvm32dlStXoqGhQfopKysb9r0Q/cMWqoffy0He5WYAwEe/nSlNOPxEYA3YrurzJYnSgiQIwIEicdKbEeVv1f+fGB5MYMzE6f5ebvj6SLmRsWoNsSiDN4yLa8QwQ0tnt/R/k2EsT2ZE+SM5NgD5VeJcU9nYbvT9t4UXhRnGwd5aAMC0CF9pDiShsX2xqoETGBgIZ2fnXt6aqqqqXl4dUwRBwAcffIBFixbBzc2t33OdnJwwY8YM5OebnwC1Wi28vb2NfgjrwBYqftedVVBts4WKZTewuiV8XZPPlyRKuyqqayI/ZkT5S3WT6lo7sSYj32aLFW8YP32zWNfkcmOHNG7JMJYfzFv8+ZLEXnWTbOU54Q3jysYO6RrIMJYHVg1Rubm5ISEhAenp6bj33nul4+np6fjFL37R73P37NmDCxcuYPHixQP+P4Ig4NixY5gyZcqIr5kYOTOi/FHX2omzFU0AgA27C6RYtTXFojx8uX0AUl0KAFTXRGbwYc2qpnajuknscWsvVHy4wc2lZ9/nYlhAAVC4QWaw73h2QXWfdZOsDa/DefHfp/BRdglyi+sAgAxjGWD1LKoVK1Zg0aJFmD59OpKSkvDuu++itLQUTzzxBAAxfHTx4kV8/PHHRs/buHEjZs2ahcmTJ/d6zZdffhmJiYmIi4tDY2Mj1q9fj2PHjuHNN9+09u0Q/cAvVB5uzjhbcQ6AbReqvmBCY4DSN+UGb4zuOlcFwLhuki2NUVPDuJsMY9li2g5GywmMbeU54Q1jP6+eSIOrMxnGcsDqBs6CBQtQU1ODV155BRUVFZg8eTJ27NghZUVVVFSgtLTU6DkNDQ3YunUr1q1bZ/Y16+vrsXTpUlRWVsLHxwdTp07F3r17MXPmTGvfDtEP/OKw42SFeExj+4WKT99s6ejGO3sLUWvjho3E4DFXN+mRpEh88HOxna6oh9gxXmQYyxQWHmIC485uvU3qJpnD1DDu0pFhLAds0qrhySefxJNPPmn2sU2bNvU65uPjg9bWvusJrFmzBmvWrLHU5REWwtxCddd1Ifjm6CWbXodpXRNWYJDqmiiHD34utnrdJFN4w7i8rg1fHipDwZUWq/6fxPBh3/OWzm7kVzXbrG7SYJgZ7UeGsQygXlSEVfnm6CWbL1R9pW9SXRP5otMLuH1yMHacEhMSbFk3if8/2GLU3NGNLw+J2ZZU10R+8HWTbvq/XQBEL4qtylHw8IbxsbI6/HTuiqTDIewLGTiERdHpBfxqVoRU9MoeCxWDpW9e5euOi/XtuCbMh+qayAxet/XAW2LxTycN7LJQUV0T5cAX+WNp/V89kYR//HjeZnWTGLxhfKi4Fj+duyKJ5J++ZRwZxnaEDBzCIvAL1ZKPcwEAGthnoQLMF/xzdXai9E2ZwS9Uh0rEXe+r907Bd8cv2XyhYjDD2N/TFbWtXZgTP4YMY5lhKjDWaICfzlb1Kkdha6FxTmHPmO3U6aXHyTC2DzYp9EeoH77AX/oZMRNm8Q3RNivwZwpf1+SRJFHQfrikjuqayAy+bpKLoSDayfIGm9VNMoU3jGtbuwAAQaO1ZBjLkBlR/pgUKtY0EwTgjV0XbF7kjye3uBYHimqhNZQZeCAhjAr+2Rny4BAWgd9RjXZ3QVN7N8rr2uyyowJgtFP6852T8HF2CQDj9E1CHsyI8kdnt17y4Hx+sNTmdZMYfLjhmc+P4LsTFfjX4XIIoLomcmN5ajxGu7vgzCWxtyAfDre1EWrOYzx+7GgyjO0MGTiExZgR5Q9BEJBtKLf/w+lKuy1UDHN6CmZokdtYHixPjcd1Eb74zYdiaNOeCxU/Fp6bNx7fnaiAADKM5QQvMP76yEUAtu13Zw7eMP7luznILqzBqu/PQi+QYWxPyMAhLMby1HiU1bZi9t/FrAZXZ43dFioG01OMGaXFleYOJMX4k55CJvAL1fv7xFR+ewmMzV3bwaIePQUZxvKB122dqRC9Nxt+PQ0fZRXbTbfFj4Xf3hCN7MIa6IWetHXCPpAGhxgxa9LzJJ3E//14HoAoMO7SiWXT7dX3iXcbX2kW+8R4e7iS21gm8Lqtny+IC9P/3DbBbrotntziWmQX1mKUVtwD3jElhPQUMoHXbbFP4WBRrd10Wzxr0vPw9u4L0t+dOr10LdQDz/aQgUOMGH6h+va4WNTvvmlhdl+oeKHxAwlhAIAfT18mobFM4Bcqd1dxKsq73GT3hYo3jJs7ugEA0YFeZBjLiBlR/rgu3EfqQbVxf5FdBcaM3OJaHC6tlwzgXydGkGFsR8jAIUYMv1D5eboCAKqbO+y+ULHO4gCwcv4E6TjTU1CIwf7MiPLHrGh/tHeJKbVfH7lo94WKN4xvHj8GAPDm7gtkGMuI5anx+M310dLfprote3y3ecOYjdtrw3zJMLYjpMEhLAKb9FkMfE/eFbsLjBkkNJYvy1PjcaysHve8+TMA+wqM+WtiPDEnFrvO9xRuIz2FfeF1W5/miJmRctFt8ULje9/8GUfL6vH7rSdIaGxHyMAhLMLy1Hg0d3Rj8os/ApCHwJjBhMa+Hq6ob+tCyoQgEhrbGX6h2rBL1CzYszBkX9eYXVAt/c30FGQY2w9eYMzaIfzlnsnYfqLCbgJjBj8WfjkzAkfL6klobGcoREVYjFe3n5F+57vp2hPebVzfJhZuC/F1J7exneF1WzvPXAYAPJocZXfdFk9ucS0OFtfBzVmcJh+aHk56CjvDh8Ndne1fGLIvjpb19KLihcaEbSEPDjEi1nAT/RcHxeaE148LwKzoAKxOz0NWQTU2L02y2/XxbuMnPz2MHacq8VlOKRVuszN8YUjmWSuva7VbYUhTzBVum3yVN8rryDC2NzOi/NGl00senM25ZbIJhwPAwnezkVPYY6D/bk6s1GgYAHn+bAgZOMSIYDtxAEiI9MXhknrEBY2WHs8prLXrQsVPJGlz47DjVCUEkNtYDpjqtjLOVslmoeIN44feycLBojq89O1p0lPIgOWp8UiKDcDCd3MAyEO3xVifmS8ZN6yi+80TguDh5izNkxQStx1k4BAjIi0lDlkF1cgprEVNcycAoLyuFZuyiqUvsr13VIDoaTpQZNwIj/QU9mV5ajwa27twzUs7AchLt8WPhV8nRuFgUR3pKewMr9t6d28BALHJppx0W8wwBiAZNHmXm6THE2P87T62HQkycIgRs3lpEtZn5ktfaH4nLhdyi2uRU1gLd1cntHfpcf+0q0hoLAP+uv2s9Duf3SYncot6wg28YUzYFl5gzLx+S2+MkTQ4coA3sPbmXcGhkjr8779PQS9AdnOiI0AGDmERfnN9lGTg8DtxOWBOT3F1qA8qGtpJT2EHeN3W5lxRtzU7LhAzovxlodviYXoKDQABwH/dGEN6CjvB67a83V3Q2N6Nkmr56LZMWTAjHIdKejx/crkuR4IMHGLY8C7jV3cY78Tl4jIGjPUUC97JxoGiWvy/7WdIT2EneN3WtAhfHCmVl26LwespfDxdUd/ahRvjx8BL60J6CjthqtuSQ0NfU9i8WNnQLh3jM6nIKLYdZOAQw8acy/iGcYHQC4JsXMaAsdv44VkROFBUS3oKO2JOt1VW24IPfq6SlW7LnJ4in/QUdmV5ajzqWjox9S/pAOSl22LwBjyDz6Qio9h2kIFDDBveZRzq445LDe1o6ezG0dJ6WbqMARjVVyE9hf0w1W2ly1C3xRvG+/Ov4GBxHV75zxnSU9iZVd+fk36Xq26LwUJpNS0d9r4Uh4QMHGJEmLqMj5bWy85lzCA9hbx4NEm+ui1TfjkrAgeLSU9hL3jd1peHRN3WTePHYFqEn+x0W+Y8f18eKpeVd9JRIAOHGBHMIIh6YTsAwMVJfi5jwERPYSgsN4f0FDaH12399Xv56rYY7HovN5Kewp7wYZ+p4b44WlaPuKBR0uNy0W0Bxp6/tRl50Ativyw5XJujQQYOMSz4her/fuxxGXfr5blQmdVTVDVLj5OewjaY023NiR+DLp1eVrothjk9xRNzYsgotjFGuq0WUbdVUtOKnWcuy9Izwhr8skvSC6C6W3aADBxiWJhbqMZ6axE7ZpQsFyp+MtmXfwW5xXV4+bvTpKewMbxuK8TbHRWN7Wju6MLhEvnqthhMT1FrWGAJ22Kq22LGjRzHCmvwOyXMByfLG+BpqGRMdbdsCzXbJIYF3/QudowXAMDdxVl2Te/M8fCsCAAgPYWdmBHlj+TYAFQYwj6HS0Td1udLErEiNV5WO3Hm+VuRGo/G9m4APXoKuV2rI/BocpT0u1x1W3zdrZPlDQCA1k4dZkT5Ud0tG0MeHGLYmAqMS2pbZSswZqxJz8Ou81XS39SywfYoRbcFkJ5CDvDh8FUyrrfF4Otu8R6n3OI6qrtlY8jAIYYNm1SiV26HIECahAD5LgC5xbU4YdhVAT16CnId2xZT3ZZcw1KM9Zn5ZvUUhPUxFw6fHRcInV5e9bYYRg1+U+KwJiNPmh+p7pZtoRAVMSLWZ+ZDMEz8OsNCJVd41zHjpvFBUkiNXMfWZU16HtZn5mN9Zj7e3CU2SwwarcWK1HisTs/Dwnez7XyF5ln4bjZWp+fhlzPDAQBeBj0Fu5c1JiJkwrLw4fAQH3cAQEtHtyLC4UqaH9UIeXCIIcPXpOAzTFi1TjnVpODhXcc3/2M3iqpb8Kv3D0CnF8h1bAP4jKTbrg7GD6crETtGnqm+DL68gL+XGwCgpVOHJ2+iyrS2xDQcfkTG9bYYrO5W6qQgpJ+pQmSAJ9XdsjFk4BBDhl+ofp0YiU9zSuDr6QoPN2cA8lyoAGPX8bxJY/HO3kLo9AK1bLARfKpvraGya0tnN1an58ky1RfoXV5glNYFzR09mVRUXsA2KEm3BZgaxloAQLdOkLyVABnGtsAmIaoNGzYgOjoa7u7uSEhIwL59+/o8d/fu3dBoNL1+zp07Z3Te1q1bMWnSJGi1WkyaNAnbtm2z9m0QBtJS4pAYI+6o6gwTvaers7RQKSG7pKi6BQCggXHhNsK6bF6ahBWp8ThYXAcAOFHeIO3E01LiZLejXc5d24rUeDR3iJlUm3PLsCI1XpaeSrXyz53npd+7ZR7u4bPvtuSKlZcvNbShS6cHQIaxrdAIgmDVlWjLli1YtGgRNmzYgOuvvx7vvPMO3n//fZw5cwYRERG9zt+9ezduvvlmnD9/Ht7e3tLxMWPGwNlZ9BBkZ2dj9uzZ+Mtf/oJ7770X27Ztw//+7/9i//79mDVr1oDX1NjYCB8fHzQ0NBj9H8TQ4DMEAGXUk2EFuJirO9THHQtnRmB1ep4UppLbIqtGol/YDgHiTvzCX2+39+UMmpiV26VMqsJVd9j7clSPuXC4n6crfnN9NFan5yExxl/2RqYS50k5M5T12+oenNWrV2Px4sV4/PHHMXHiRKxduxbh4eF46623+n1eUFAQgoODpR9m3ADA2rVrkZqaipUrV2LChAlYuXIlUlJSsHbtWivfDcGTlhIHw9wDZ408a1KYwoybGVF+AIBLDe14fHa0JFbkm3ES1mFteh7YrkruO3Eec5lUhHVh4fDV6Xm4fUoIACDGjG5LzqSlxMEwTRqF1gjrY1UDp7OzE4cPH8a8efOMjs+bNw9ZWVn9Pnfq1KkICQlBSkoKdu3aZfRYdnZ2r9e89dZb+3zNjo4ONDY2Gv0QI4ef8HWCMhYqVmQut7gO7q7i8P/rjrNSRgYJja0Dn0G11jBO3F2dsHxunKwzqBgsk+r+aWEARC8CZVJZH+NwuKjbau/SKSocvj4zX5EGvRqwqsi4uroaOp0OY8eONTo+duxYVFZWmn1OSEgI3n33XSQkJKCjowOffPIJUlJSsHv3btx4440AgMrKyiG95qpVq/Dyyy9b4I4IwDjM4+KkQbdewGPJUVKtCjmHedh18W7jT3NKyW1sZXhh+i+uC8W/j11CTOAoaDTi3lauwnTAVDDqCgBoau/GsylxJBi1AaYtGk5falTM95VlUs2OC8S+/GqMDx5NmVQ2xCZZVGwSYwiC0OsYY/z48Rg/frz0d1JSEsrKyvCPf/xDMnCG+porV67EihUrpL8bGxsRHh4+5PsgRJhxkxDpi8Ml9XBx0uCPd0xE3uUmWRbeMkdaSpxUmVYp4TUlw2dQMWF6t14v6wwqhmkmFTPqG9q6AJBg1BakpcRhjSG0qZQwD28Y+3mKJQZcnDSUSWVDrGrgBAYGwtnZuZdnpaqqqpcHpj8SExPx6aefSn8HBwcP6TW1Wi20Wu0QrpzoD9OaFBEBnnhrd4GiwjzmwmtKmDSVjOlOPO9ysyJ24qY7bHb9m7KKFXH9amBdRm/dltzfd1PDGAAKr7SA5fWQYWx9rJ5FNWvWLCQkJGDDhg3SsUmTJuEXv/gFVq1aNajXeOCBB1BbW4uffvoJALBgwQI0NTVhx44d0jnz58+Hr68vvvjiiwFfj7KoLMNvPjyIXeevQKMBBAV15WZu47uvDcW3xy8haLQWVU0dRp4EchtbD5ZB5eykQYGCMqgYLJPKWaNBwSrlXb9SMJdB5eykwdM3j8O6zHxFZFAx1qTnYR2nvVHKXClHZJVFtWLFCrz//vv44IMPcPbsWSxfvhylpaV44oknAIjho0ceeUQ6f+3atfjmm2+Qn5+P06dPY+XKldi6dSuefvpp6Zxnn30WO3fuxGuvvYZz587htddeQ0ZGBpYtW2bt2yE4Ivw9AYjGjVK6cpvTU7R0dEti19XcpEpYHl5wqcTS9UoU1isVPoPqgQRR3B3h7yl9P5WQQcXgN0xKCbGpAatrcBYsWICamhq88sorqKiowOTJk7Fjxw5ERkYCACoqKlBaWiqd39nZieeffx4XL16Eh4cHrr76amzfvh23396zU0pOTsbmzZvxpz/9CX/+858RGxuLLVu2DKoGDmE5dp2/AkCciPiu3HLG1G2s0Yil91s6dADIbWwN+mrt8cwt42Td2sMU5vm7fXIwdpyqxFW+7iQYtSLmKl9rAEXotkzhDTGlhNjUgNVDVHKEQlTDx9xitfV3Sfj5Qo1iCm8xqACXbeDf5wUzwrEltwxX+XpgwYxwI7GlnN97/h5+NSsCnx0oRYCXGx41ZA8C8r8HpaL07ykzjKdH+eFQcR2uC/fBsbIGCokPE1mFqAh1wbuNGTGByiq8xUhLiQNLvHMmt7HV4GuZsJ24i2EcKaWWCV96/7MDose5pqUT7V3k+bM2Sv6eGoXEDZlUo7SuUiYVhcStCzXbJIYE7zYGxA7Ln+SUKNZtzPyXOnIbWxXTDKqS2lZF7cT7yqTasLtAUfehRJT8PTWXSVVwpRkzo0WDnwxj60IhKgpRDYsnPz2MHacqoQEgQLlu47kTg5BxtgpRAZ4ormklt7GViV65HYKg3AwqhtIzweROX7qtJ+bE4O09hYoKhTNe+/4c3tpTIP2ttDlTLlCIirA6cWNHAxCNG6VkUDGMCnB5iW5jnSCQ29jKmNuJKxGlZ4IpAT4UvihJTEjxdneBh6vYk1BJoXDG7+dPkH6nTCrbQCEqYlj8eFostOisUU4GFcOc27i8rg3dOj0AchtbGr61h7NGA50gYPEN0Ypo7WEK8/zNiR+DPXlXMG7MKMqksgLmKl97urlgTUa+4kLhDMqksj1k4BCDhncbn6tsAgC88fBU5Fc1Kyrdl1+ABEHAmgzRs7D+pwvkNrYCzLiZFuGLI6X1cHN2wh9un4izFY2Kae0BmNZQEj1/Tk6g0vtWwlS3VdnYrtjvJzOMJ4aMxtmKJlwfG0CGsQ2gEBUxaHi3sdZFHDpRgV7S40p0Gz87Nx4sGEVuY+vAOrgfKa0HAIT7e+DNXRcU1doDMM6k2nb0IgCguKYVeiq9bzXSUuLAosVK7RlnridVsI8HhcRtAHlwiEHDu407usVwzo6TFXjd4PkAlOk2VlqPG6XBdqa/3XQQP527gsLqFinrTknvNb/D1gsC1mbko7Nbj7WGsImS7kUpqKFnnLmQeHFNCyIDxErwZBhbD8qioiyqIfPC1hPYnFsm/a3UyZ25jRNj/JFTWIvJod44damRMqmsxCvfncEHPxcBEIXpea/Ot/MVjYyoF7YDED1/FyiTyqLwui0PV2e0denw68QIfJpTKnn9lPjd/OO2k1IdJUC5c6c9oSwqwqrwIQWlZVAxzLmNPbUu5Da2IrvOVwEwbu2hVMwJRgnLwYybmVF+aDMUU1w5fyKSYwOQVVCD3OJaO1/h8Fh5+0Tpd1dnZYbclASFqIgh8+Uh0XvjpIHiMqgY5tzGJTUtuGFcIAByG1sKXpheVN0CAPjktzNxqKROUcJ0Hub5S4jwxeHSekyL8CXBqIVhmygmQh8zWouN+4sUp9sy5YP9RdLvXTplhtyUBBk4xKDgF6oDReLu6YX5E9DepVfkQsUvQO1dOmzYXYDLjR2K1IbIGSZMB0SDWC+IwvRDJXUAeoTpSnm/ec+fr8Hz5+vpRplUFoZ9P1lB0eom5X83mWF8la87Lta34/bJwWQYWxkKURGDgs+gChqtBQBEBSg7g4rxP7dRAS5rwfeh0guA1sUJXx0qU1QfKh4+kyrznBhyK65pkR4nz59lGR8saiyUWFCUx5xhPD7Ym0LiVoY8OMSg4DOo6lu7AAA/X6jGR9klis2gYlABLuuyeWkSlm85hm1HL6KzWy8Va1Pie8zvsBvbuvD+/iIUXlFmVpgS+OF0BQBlFhTl6SuTKtpQZoMMY+tABg4xaDYvTcKqHWfxzt5CAJCMGyV/MVkhsQnBo3Gusgk3jOspwKXk+5Ib14T5YNvRi4rfifP84faJeN+gqSDBqOVZn5mPsxViQdHXH56KC4aCooDyvpu8YZx3uQn/OVGBbwzfB6XPoXKGQlTEkJg7aaz0u9IXKmbcJMcG4LbJwQCAUN+eAlwPv5eDNVyMnBg+/z4mFsbjhelK541dF6TfmWCUGDlrDN+91el5cHc1FBQN8EJaShySDRWAlfxeP3nTOADKD7spAfLgEEPiPYP3RgPlZlAxdHpBSjv19XAFABRXt+LvD1yLnMIaZBXUIDEmwM5XqVx4YfqxsgYAwKr7pkhibqUJ03mYYDQm0AuF1S24ZcIYEoxaCGcnjZQifrBYFKNHBXpifWa+lEWl1HA4AHx/qkL6XelzqNwhA4cYNOsz87HzzGUAwK8SIxA02l2xLmOgx23M97sprmmRJlJyHY8MPoPK28MFjW3diArwwuXGDgDKy6BiGHejdwWqgaiAUViR6keZVBaAjQf2XgaN1uL9fUWq0Dmtz8zH6z9dgJfWGS0dOvxyZrii51C5QwYOMSB8VdG4oFHIr2pGVIAXHp8dg5zCGsV/QdNS4qRU8SoVpKPKBV6Y3tTWDQD46VwV3tlbqGhhel+C0es8fQGQYNQSpKXE4VxFI3acqsQVlXwn+ZC4Ti/gQFEtZkb7I8THA6vT85BTWKPYCs1yhQwcYkCYyzg5NgB1hgyq6EAv1biMATFVfMPuAgCUKm5JNi9NwkvfnsamrGIAkIwbJb+//AJUWtuKfx0ux0/nqvDTuSrF35uciA8ejR2nKlWjVeFD4pOvEtPfi6pbsSI1nkLiVoJExsSApKXEYUVqPLIKanChSsxq2JdfLe2qPl+SqPhdB5Xetx6sOjSgjoWKZ9ncnnuhTCrL8sOpSgDGKeJKZrlhrlyRGo9TFxsBAMXVFBK3JuTBIQZFWkocmju68a5BZLwpq1g1X0gmGJ0YMhpnK5pwPZcqDpBgdKR8klMMQNmtPfpi6+Fy6XcqvT9yeGH6uUpxM/XGw1ORb0gRV7IwnZGWEof8y8347sQlfHf8EqWKWxEycIhBc8uEIMnAUctO3KjCqIdYYTTUx4NK748QfqHak1cNQEyPdXNxUs1CxQxjfy831LZ04r5pV5FhPEJ4Ybq7qxPau/SICvRCflUzAOUK0015+pZx+O7EJdWE3+QKhaiIQbNxnyFFXEW1TPjS+9mFYmM/Kr0/cvjWHuF+HgDEHlQMJbf2AEwNY7HEwNRwXyq9P0L41h7tXXoAwI6TFYpt7dEX209ckn5Xy1wqR8iDQ/QLvxNPPyv23nkkMRIBo7Sq2InzO+zKhnZ8frAUucV1yC2uI7fxCDDX2uNQcS0255YpOoOKYS6Tqqi6Fb6eorFDhvHw2bw0CSu/PoEvDpYBAF7/6YKqvovM8zda64Kmjm4snBFOnj8rQQYO0S+8y3jcGC9cuNKCqEAvNLWLab9qcRkDwO/nT8DnB0sBkGDUEmxemoTVO89j/U9ixV9m3KjhfeUXoONl9cg8V4UPs4ogCKSnsASzogMkA0dNIRzjppuuaOroxvQof4T6elBI3ApQiIroF95lzFLET5Q3qM5lDAAfGVKZASq9bynuuCZU+l1NCxXPb2+IBgAIgnrv0dZszhU3Gmpq7QEYh8TL6toAiJlUDPL8WRby4BADsnlpEtZl5GFNhjjJbDt6UXW7VOY2DvFxR0VDO+6YEkJuYwvwpqFfkxpae/TFrnNV0u9qvUdbwIfDmZfjv2+dgC6dXhXhcMDY83eouBZ786uxYfcF6MnzZxXIg0MMiodmhEu/qy18Y+o2BoBJod4kGB0h6zPz8e1xUUx5+zUh0vuplt04IN7j+/uLpPGx+IZo1d2jreCF6cHe7gCA6EBP6XGlC9NN+XViJABAT54/q0EeHGJQ8N4MtdX7MC8YbUGEvzi5ktt4aPCtPa4L98GxsgZE+nsiLSVOFa09GHzp/StNHcivasac+DHw8XCl0vvDgBem17V2AgB+LqjBJ9klqhCmm7L/QrX0O3n+rAMZOESf8C7jrw6JBc1mxwViRpS/alzGgLHb+FxlE3acrMDWw+VUgGuY8K09XJ1FJ3GEv3q6QTP40vsxhhT4kpoWyZCj0vtDZ/PSJLz2/Tm8tUdsm8KMG7V9B1lInPG7ObEUErcCNglRbdiwAdHR0XB3d0dCQgL27dvX57lff/01UlNTMWbMGHh7eyMpKQk//vij0TmbNm2CRqPp9dPe3m7tW3EoeJfxrGhRaMy8GoD6XMYA8MScGACgAlwjgG/tcby8HgBwqKROVa09AOPS+4UGoWhRdSuV3h8h864eK/2uxu8gHxL30joDAG6dHEwhcStgdQNny5YtWLZsGf74xz/i6NGjmD17NubPn4/S0lKz5+/duxepqanYsWMHDh8+jJtvvhl33XUXjh49anSet7c3KioqjH7c3d2tfTsOBZ9BVd8mZlCV1raqMoOKwfrfAOrK3rA1aSlxWDY3TqqB86/D5apd8NNS4pAyIQgA8GFWkSo6X9uT9wzV0nlhuprgM6laOnQARM8fg0LilkMjCIJVV6hZs2Zh2rRpeOutt6RjEydOxD333INVq1YN6jWuvvpqLFiwAP/7v/8LQPTgLFu2DPX19cO6psbGRvj4+KChoQHe3t7Deg1HgmkNGGqdvNl9al2c0NGtx6LESHySo04XuS0oq23F7L/vAiDuxPNenW/nK7Ie+/Or8euNBwCo/16tCT/XPJgQhnB/T1UbjLev34czlxrhrNFAJwiqvU9LMpT126oenM7OThw+fBjz5s0zOj5v3jxkZWUN6jX0ej2amprg7+9vdLy5uRmRkZEICwvDnXfe2cvDw9PR0YHGxkajH2Lw8F84Fyd1ZVAxeMHo+ODRAIDrxwVKbuOH38vBGs7IIwZmHbfzVuNOnGfX+d6p4sTgWWP4jq1Oz8OkUHHRigwQhenJsQGqzUybf3UwAEAnCKoMx9kbq4qMq6urodPpMHbsWKPjY8eORWVlZR/PMuaf//wnWlpa8NBDD0nHJkyYgE2bNmHKlClobGzEunXrcP311+P48eOIi+s9QFatWoWXX355ZDfjwPzfj+ek37v16sqgYvCC0fixowAApbUkGB0qvDD9X4ZO2zePH4OpEX6qEqbzMMGok0ZM+V0yO5oEo0OEF6Z368SgQrgKhemmnK0QN9tqrhNlT2ySRaXRGAumBEHodcwcX3zxBV566SX8+9//RlBQkHQ8MTERiYmJ0t/XX389pk2bhtdffx3r16/v9TorV67EihUrpL8bGxsRHh7e6zyiN+sz8/HmLjGjIcDLDY8mR6kmzZeHLUC8i7ykhgSjQ4Vv7TEjyg+5xXVmhelqeS95wai3uyvq27qQMnEsRru7Uun9IcDGw+r0PEl4m1NYiy8Olqr2u7c+Mx87DJq/IG8tfjUrUpVzqz2xqoETGBgIZ2fnXt6aqqqqXl4dU7Zs2YLFixfjq6++wty5c/s918nJCTNmzEB+vnkXplarhVarHdrFOzh8LZM7p4TgPycrEBGgvlompqSlxOHUxQbsPHMZnx8spd5CQ8Rck83imlZ8pNJaJuZqKJXWtEqPk2B08KSlxKFbp5d6l6nZuGFev9/NicVbewpwubEDS2aLGZxq9XTaA6tqcNzc3JCQkID09HSj4+np6UhOTu7zeV988QUee+wxfP7557jjjjsG/H8EQcCxY8cQEhIy4msmRHiX8dVX+QAAIh3AZQwAv7meeguNhM1Lk7AiNR75Vc0AgD15V6SFKi0lTlXhmuXcfV0TJn5PXvj6hCSMpUVqaNx1rfp7l/G4uzphtLvoZyitbR3gbGKoWD1EtWLFCixatAjTp09HUlIS3n33XZSWluKJJ54AIIaPLl68iI8//hiAaNw88sgjWLduHRITEyXvj4eHB3x8xAnk5ZdfRmJiIuLi4tDY2Ij169fj2LFjePPNN619Ow4D7zJuahd34pWN7fjm2CXV7qoYP527LP1OcfHh8cwt4ySPhtpae/TFXdeE4kR5A5XeHwFvOEDvMkDcBLBweNBoLZrau/Hmrgv49rj651dbYnUDZ8GCBaipqcErr7yCiooKTJ48GTt27EBkpNiHo6KiwqgmzjvvvIPu7m489dRTeOqpp6Tjjz76KDZt2gQAqK+vx9KlS1FZWQkfHx9MnToVe/fuxcyZM619Ow4Fb+QAYkxc7V++9Zn5eG+f2FtIpxew+Ppo1YbjrMnffzgv/a621h59cfJiAwD1L87WYn1mPv59TOxdNn9KMCYEe6v6u2c6v5JxY3msXgdHjlAdnKER9cJ2AGKK+IW/3m7nq7EefKr45cZ2FFxpwSeLZ+Joab10nHoLDQwv1B7LiSfVPHnz9+zr6YrfGgxjNd+zpTDXu+yJObF4Yf4EPPxejupF/jErt0MvAE4aoHDVwJIMR0c2dXAI5cPXfmEp4mqFTxVn8qKSmlapFkdWQQ2VUO8HvpbJ7ZPF+h6R/l6qr2XCjBvWzqS+tQuPJkdRDaVBwuv9/DzdAKizd5k51mfmS3ONXoAqvx/2hJptEn2yPjNfKtbm7upk1BBOjbspc6nipbWUKj5Y+IVqYog3dpyqRESA+hcq3jD2dHNGa6cOpQbDmGooDQwfqvHzdAUAHCmtU3V7D6BnnnkwIQxfHS6Hr4erqudXe0AGDtEL3mV879SrsO3oRUT4e+LZufE4UFSr+i9hWkocjpTWYff5K3hvXyGlig8SfqFivcsu1bepfqEyW0OptgW7zleRYTxI0lLioBcErM0QN1RqHzN8OHx5ajy+OlyO5o5uLEuJw+r0POQU1lA43AJQiIroBb8TnxrhCwCI8PdS/U6c55EkUQRPqeJDg3USP3NJrNDqSAt8WkocJoaIbT6e/eIYaXCGyIPTe4qvqv07x3v9vjpUBjcXJ3TrBdyfEEbhcAtCHhyiF/xOvKNL7HZb29LhUBP23rwr0u+UETM00gy7UEC9vcv64targ3G2ool6Cw2DtZxOSe3fOVOvn5+nKzq79VibQeFwS0IGDmEW0xTGI6X1DvOlY1VGGU/MiaHeQkNg9c6eFHG19i7ri/OVTQAoVXyw8L3LvjL0LrsxfgymR6q3dxmP6Ty79Yi6Q3O2hkJURJ+kpcSBOUkdZSfO9xYapRXt/9RJwVJGzGpuQiZ6sz4zXyq1P1rrguVz41SbPWXK+sx8fG/oLRTq6yGNGUe49+HCepetTs/DzCg/AGLFdAbrXaZm0lLiwKYUJ416tY32gAwcok/WZeSBKW3UniLOYL2FVqTGo7mjG4DYVZxBvYXMw6eI/+I6sdx+RIAoTFdzijhj4bvZWJ2eh/+6UewndKmhDf81J0Yycha+m23nK5QnaSlxSIwxpNcbhOmltS1SOHxFarzq9X6UKm49KERFGMG7jNcYMhqcNMAzt8Q5hMuYDz39eLoSpy814vkvT0AnCOQ67gdemH5NmC/+fewSIh0gRdwUTzdnKVW8vK7N3pejCPi2BQCwJ6/aYb5rLBzOslUDR7lRONyCkIFDGMFcxgCwYEY4tuSWIcTHQzJ6mMvYESaf26eE4PSlRhKMDgJeS9DaKXq+rjR1YMdJxxCm84t04Cg3tHbq8MZPF7Dt6EWHuP+RwgvTHaV3GR8O9/EQ6/+0duqksC4AqVM9MTwoREUYwbuMG1pFl7GTBg7lMmawVGdeMEr0DUsRP1Ym9mTKLa5zqMWd3X91cycAkHEzBP7+wznpd9a7TO3w4fBNWcUARAOntVPMXKVw+MghDw7RC1OXcVldm8NN1Osz87H9ZAUAIHC0FosSI1Vf4NASOHKKOCDe/9qMPKm3kKPd/3BYn5mPDbsLAABjHOi7Zhp6Yvf8zt5Ch5tvrQV5cAiz8Mp+Z41jLVRMMPrkTbEAxFDL47OjSTA6CNZmOE7vMnOQYHTw8ML0O6aEABB7UKm9d5k5+IxVZwfcGFgL8uAQZuEnap3gWLVMGO6uzvB2d0FjezdKa1vtfTmyhRems1L7rs4aPHXzOIcQpjOYYPS+aVfh6yMX4e9FgtH+4IXpk0K9sf1kBSIdpMmmKesz86WMVZ2D1Y6yJmTgEL1g4SmWDfKrWREO4TJm8CG6oNFaNLZ3Y8OuAnx7/BK5js3AC9MfSAjDvw6XI8zPE04axxGm84JRX4NgtKWjmwSj/cAL0xsNKeIVDW342sG0S2yuuWFcIPZfqMbEkNEONd9aEzJwCAm+yebTN4/DG7vEgm3/c9sEFFW3ONSXzrTCKBk3fZOWEoesgmrkFNaioVUU2AqCIAnTAah+J84Eo4A4ZjQaoKNbjxYSjPaL6fcsu7DWob5nfNPNh2dFYP+Fari7OkvhcGq6OTLIwCEkeJfxHdeE4I1dF+Dr6YqPsoodzmUMkGB0KJgK04trWh1qoepLMPouCUYHxJGF6XzTzehALwBAaU0r0lLikFNYg6yCGiTGBNj5KpULiYwJCZbmmlVQgw27xKwGdxcnaSf++ZJEh9pJkGB0aBgJ0x1soeIhwejQWJ3eu3eZo7DcMK+uSI3HZwdKAQA1LZ34x4/nqemmBSADhzCCGTnfnbgEAKhs7HDILxnzRjyYEAZA1FU4UlbHcDASpjvYQsVjTjBKmGd9Zj7WZ4qhcE83Z4fqXcbD5l3GG7suOOS8a2nIwCF64ejN3/i4+DLDpNPc0Y1lBlf6w+/lYA2XHUP0vGdaF3FKeSQp0iEXKvY+zI4LBACMDx7tkO/DQPAp4vdOvQqAmCLuKL3LzOGIzY2tDRk4RC8cPTTDx8W/OlQGN2cndOsF3J8QJh2njuIi/EL15E2x6OjWAwBWzp/ocAsVbxj/alYEAMCDE4ySYdwDr/e7LtwXgGjgOGKKOIP3/DlaqM5akMiYMIJN0j4ermho68KD08McKnsK6BGMsvfCz9MVna16rM3Ip7i4CfxCddvkYGzYXYCg0Vq8t6/Q4RYq3jCOGTMKAFBaS4JRc/DZU+1dYqZZTUuHpPdztO8Xm2sSo/2RU1SLKWE+DjfvWgMycAgJVqhsWUqclCK+IjUe4X6eDlWwjWGawrr1SLlDTr79wb9H7+wpBCAW+XPEhcrUMAaA2pZO/N+P58gwNoPp9+twSb1Dvke85+/eqVchp6gWPu6ulCpuAShERfSiqb0b3XoBbi5OGDva3d6XY1ccXY80GJhAkvXuuljf7pALFcNUMPrmrgKHfj/6g3Qnxp6/3OI6AEBJbYvUsoJC4sOHDBxCYvPSJKxIjcfGn4sAAOF+Hnhj1wVpN+5I3huGo+uRBosj9y4zBy3cg2NdRp7D6074VPEvD5UBAC7Vt2NNeh55/kYIhagII9JS4nC8vB6ZZ6tQaKhe7KhfMBayu+e6UHxz7BLGjNJSb6E+oN5lxpgTjDry+8HD9y5bY+hd5qQBnrklziFD4Yy0lDgIgoA1GfnQ6QWsy8x32LnXUpAHh+jFOINAUhAAN2cnh/yCGfUW8hR7C7V16aQ6Hau5SdrRYRqCUVpxv7RwZrhDZU+ZIglGY/wBAFOu8nHo98MU1rtsdXoeHpoeDgAI9fWQvk+sd5kj8uzcePL8WRAycIheZJ6tAiBORJ06vUNONqy30IrUeGzKKgEg1sJp66LeQjwL383G6vQ8pN0yDi2d3QCA/543XhJILnw3285XaFt4weiDCeLi7e3hQqniHGkpcZLxV2/oXeakgeQtXpEa7zCZd6ZQqrhloRAVAcDYbXzhSjMA4N1FCTh9qdEh3cZ99RZ6ew/1FjJHY3s3BAEYpXWBv5ebvS/HbvCC0XB/TwBASU0rPns8kVLFOUx7l5XWtjn894qFxKdF+OJIaT0SIn0pJD5CyINDADB2G7s5i8MiMsBTetyR3cbUW6hvmDB9U1YxACDc3xOv/+S4wnReMLollwlG20gwagYSpvfAh8R9PMSQeOAoreT5o5D48CADhwBg7Dbu1Omh0QDfHrtEbmNQb6GBSEuJw03jxwAAzlU2OrQwnZGWEoflc8X71wsgwagZzAnTHRU+JL7r/BUAouePQSHx4WETA2fDhg2Ijo6Gu7s7EhISsG/fvn7P37NnDxISEuDu7o6YmBi8/fbbvc7ZunUrJk2aBK1Wi0mTJmHbtm3WunyHYfPSJCycKeoGBAFY/1NPw7e0lDiHdI8yN/r1sWJYYVKINwlGzRAV4AXAsYXpppBgtG/Y98rD1RkA8KtZEQ79vVrOzbOPJUcBAM5VNjmsJ9RSWN3A2bJlC5YtW4Y//vGPOHr0KGbPno358+ejtLTU7PlFRUW4/fbbMXv2bBw9ehR/+MMfkJaWhq1bt0rnZGdnY8GCBVi0aBGOHz+ORYsW4aGHHsKBAwesfTuqJ4nTBzj6QsULRhfMFHsLeWmpt5A59uSJu05HFqabQoJR8zBh+lM3x0qi/RfmT3BYYbopK2+fIP3u6kyG8UiwuoGzevVqLF68GI8//jgmTpyItWvXIjw8HG+99ZbZ899++21ERERg7dq1mDhxIh5//HH89re/xT/+8Q/pnLVr1yI1NRUrV67EhAkTsHLlSqSkpGDt2rXWvh3Vw3QDTho4/ELFC0azC2oAiG5jqjBqzPrMfBRVtwAAPvrNTGmhcuSxw4zjaRG+AICECF+Hf09MaWjrAgD4e7lhtLurna9GPrCWJwDQpSPDeCRYNYuqs7MThw8fxgsvvGB0fN68ecjKyjL7nOzsbMybN8/o2K233oqNGzeiq6sLrq6uyM7OxvLly3ud05eB09HRgY6ODunvxsbGYdyN+mGdfAGxB5Ve6MkecsRdhLneQlVNHfjnzvMkGIWYeZdbXCsZejq9gMgAT9wQF4icwhqHHTu85++2ycE4UloPf04w6ui9hUwzqMINXcRJu9UzdsL8PFBe14b5k4Md9ntkCazqwamuroZOp8PYsWONjo8dOxaVlZVmn1NZWWn2/O7ublRXV/d7Tl+vuWrVKvj4+Eg/4eHhw70lVbLGEG5ZnZ6Hq3zF3lMRAV6Sp8LRd568YBQAXue0SY4M6ySeEOkLnV6Ai5MGIT7ukqHsSJ3EeXjP39HSegBAKXn+jEhLicPsuEAAwMnyejJuYGwYXx8rvjfjg0dTSHwE2ERkrNEYf5kFQeh1bKDzTY8P5TVXrlyJhoYG6aesrGxI16922EKVHBuAbsOCFGnYVTnyQsVDgtHesKaSh0vqAQBX+Xlgw+4CabH6fEmiQ3op+FTxbUcvAgBKa1uxLoNSxXlYnSA9CdMBGBvG5fViBhUZxiPDqiGqwMBAODs79/KsVFVV9fLAMIKDg82e7+LigoCAgH7P6es1tVottFrtcG9D9bCJhS8q9cOpSry1h7ogM6i3kHnSUuJw6mIDdp65jNLaVtqJc6SlxEk9hdq6dFiTQaniPPvzRY88L0x35PfGXEi8tLZV2mjS2Bk6VvXguLm5ISEhAenp6UbH09PTkZycbPY5SUlJvc7fuXMnpk+fDldX137P6es1iYFJS4nDI0mR0t9k3PTAJpwZUX4AgOvCqbcQT/zY0QAoRdwcvAeLPH89rM/MR2mt6KX4/PFZJEznSEuJw69miVmbh0rqaNMwAqweolqxYgXef/99fPDBBzh79iyWL1+O0tJSPPHEEwDE8NEjjzwinf/EE0+gpKQEK1aswNmzZ/HBBx9g48aNeP7556Vznn32WezcuROvvfYazp07h9deew0ZGRlYtmyZtW9H1cyOGyP9TguVCB8Xv29aGADA19ON4uIc6WcvA6AUcXPw7wWlihvr/ZiiIJL0fr34n1spVdwSWL0X1YIFC1BTU4NXXnkFFRUVmDx5Mnbs2IHISNFbUFFRYVQTJzo6Gjt27MDy5cvx5ptvIjQ0FOvXr8f9998vnZOcnIzNmzfjT3/6E/785z8jNjYWW7ZswaxZs6x9O6rm0xyxqSSfIu7oXyw+Lh7q6wFAjItv+s1Mh+4txPcuO1/ZBAB48+FpyLvc5JC9y8zBegtNucobJy82IjHG3+F7CzG9H+u3pHVxQtBoLen9TPgou1j6naWKO/pcPBw0AlPwOhCNjY3w8fFBQ0MDvL297X05soCP+z4xJxaebs7kGuXg3x9XZw2eunkc1jqwpoJ/P9xdndDepcf3z85G+pnL0nFHfW8A4/fnhnGB2H+hGvdcF4qYMaMc/v3h35txQaNw97WhNNdwsPdnrLcWlxs7cPe1ofj2+CV6fwwMZf2mbuIODl/LJCrAE8U1rYgM8MQvZ0Y4dC0TU9JS4qAXBKzNyEeXTnBo4wYQ34+sgmrkFNaivUsPANh+ogJv7BJT6AE49E6c9RYCYCQYjRkzCoBj9xZKS4nDsbJ6/HSuCgVXmsm44eBD4v5ebvjPiQpcE+aDcUGjqIbSMCADx8HhU8QrG9oBUIp4XyybG4+1GaI+gASjYsG2P247ic8OiCFmZtw4+vsCGIuLLze247MDpThSWo8jpfX0HgGIHeOFn86RMN0UPiQ+05DUUFLTir/cM9mhQ+LDhbqJOzislklWQY3Uvfanc1UOX8vEHCQY7U1SLPUuG4jfzyfBqCk/nasCQMJ0U/gaSgeL6wAAJZQqPmzIg0MgLSUOje1deH9fEQDg/f1F9EUygQlGrwv3wbGyBsyI8nN4wSgAfHFQ9N6QML1vNv1cLP3uyIJRXphecEXsXfb+I9Nx8mIDCdNNSEuJQ1ltK746XI69eVewN+8KzcnDgDw4BADglglB0u+0EzdmfWY+cgprAQA+HmItpqDR7lKq+Gpu4nYk1mfm4+cLYu8y5gmkNF9jmKYi2FtsgXLXNSEO+x45O2mk74urs/h9iQjwlB7PKax1yPelL/gNE83Jw4M8OAQA4MP9ovdGQzvxXvQlGB0fLBa4czTBKC9MD/fzQFldGyIDPHHv1DASpnPwgtHAUVp8e/wSJl/lg7ixox1SMMoL07t0AjQa4N/HLmJ9JgnTzfHloZ6WQjQnDw8ycAisz8xH+lkxJr4oMRKBo7S0SHHwC1B1cwc+zi7ByYsNOHmxwSHdxrwwnem2Ivy9SJhuAi8YnRXtD0A0jF+9d4rDCkY3L03CC1tPYHNuGQQBknHjaN+hgVifmY+1Gfnw83RFXWsXHkgIozl5GJCB48DwO/H4saOQd7kZEf6eeHx2DO3E+2Dl/In4OFssiOioglFzvcvSz1Ti7T2FtFhxUG8h88yM9sfmXNE7QaGX3vCeP62LE3adv4JpEX6I8Pd0SM/fSCANjgPD78S1Ls4AgAhKEe+X9/YVSr8zwagjkpYSh8eSo6S/ybjpm7SUODw0XWzzsS+/2uHrvrDQCy9MJ3rgPX/1rV0ARMOYuooPHfLgODD8TlzrItq6+y9U4+PsEoeegPuC7axCfdxxqaEdd0wJcWgv15z4MdiUVQyAduIDsSJ1PL48VA7AcT1/gLFg/7l546HTCw79HTKHec9fi8N7/oYDeXAcnLSUODx5Uyw6usVqtGTcmId3Gycaar9MCvV26KabHxv65WhoJz4gW3J7+u05ouePb7IZ4iNmlEUGeFKTzX5IS4nDL64LBQB8f7LS4T1/w4EMHAK3Xh0s/U47cfPwbuOKerHic0lNi8O6jddn5mPX+SsAgCWzYyhFvB/WZ+ZjTUY+/L3cAAD3T7vK4d4rPhzepRPD3pEkTB+Qp28eBwAQQHPzcKAQFYF39oq6Eg0oHbEvzLmNS2ocTzDKC9NjAr1QWN2CCH9P/DoxkoTpZuA9f55uzsg4W4WpEX6IDPByKMGoOWH696cqsGF3gcN8d4bDd8cvSb/T3Dx0yMBxUPiqojtOVgAA7psWhsgAT6oq2g9pKXG4VN+GzbllOFBUiwNFtQ41QfM78aqmDgBiqIF24ubhPX9TI3wBiILRP9w+0eFSxdNS4nClqQOf5IhZiGTc9A+rnu6ldUZLhw6/nBlB1dOHCBk4DgqrKgoAV4d64/SlRkSaqSpKk09vnr91vJTm6miCUX4nzgzk3eeuYOPP1N7DHOY9f44rGL1+XKBk4FDIpW94MbavhxtaOtqQGOOPEB93aRytIONmQEiD46CkpcQhMUYsPsZSEc9VNEpCthWp8bQT74PPDBM04JiC0bSUOCyZHS2NDzJuBiYtJQ73Tr0KALDz9GWHFYx+fkD87lCKeP+w6ukrUuNxsb4NAFBqKKoJOF719OFCHhwHZvPSJKOd5Y5TlQ456Q4FJhgNHKVFdXMH7pka6pC6k5SJY/GeoTkr7cQHx9O3jMO2oxcdVjC6PjMfe/OrAQC/uykWWhdnh/zuDAY+9MRCmWsy8qAXQHP0ECAPjoOz9MYY6XdHC7cMFV4wmhDpCwC4LszXIVPFPzDTu4zon38fuyj97kjvGZ8iHukvhsEj/b0oRXyQLJgRDgDQC45pGI8E8uA4OKt2nJV+Z+EW+gKZhxeMTo/0AwCU1LbixbuudgjBKC9M33nmMgDgV7MiEDTanYTpA8AEo6O1Lmjq6MbCGeEOIxjlhenldWK4JYKE6YMmp7BG+p0yqYYGGTgOzPrMfHxk6Ks0+SpvzJsUTC7jfjBbYdSBUsV5YTrrXRbp74W2Lh0AEqb3BS8Y9fF0RVNHN2bF+CPU18MhBKO8MF1jKBWVefYy3ttH2q2BWJ+Zjy8O9nQVT7tlHM3RQ4AMHAeEr2UyJz4Qe/KqJZcx1TIZmLSUOJTUtGDrkYvIPFeFzHNVDjFRp6XEIaugGjmFtWhoE4XpJy824Nvjl6QFmnbivWGCUQBGNZScDKu9IwhG01Li0NDahY0/i6FNMm4Ghm2kkmL8cepiI5o6unH3daFwcXZyqBpKI4EMHAeEdxlHBngBqCaX8RBJS4nD1iOipsKR4uKmwnRm3DjK/Q8HfgE6UFSDny/UYH1mvsMJRm+aMEYycBzpOzNc+JD4mNFaNHV0o6SmVdqIqj0kbglIZOyApKXEYUVqPLIKarA3Tyy3f+Fyk5S6+vmSRNoVDMDXRxxTMAoAjyZFSb+TMH1o/HJmBADHFIxu+rkYAAnTB8tyw1y8IjUeVwxFNR2xevpIIA+Og2JaOj39rGOEWSwBE4z6eLiioa0LD00PcxjBKAC89uM56XcSpg+NrALHEozywvTMc1UAgMeSo+Dn6UbC9EGSlhKHvflXcKi4Dv9v+xmH8/yNBPLgODBPGRq5AbQTHyzGFUZdAQDTo/ylVHG+wq8aWZ+Zj88PiJ2xp0f6UZPNIcC/dwDwjEEwqub3jgnTV6fnYdwYLwCQUsWBHmE60T/3TQ0D4Jiev5FAHhwH5q+UIj5kzAlGy2pb4eos7hXUKhjlhenXjwvAzxdqEBHgScL0QcLXUDp9qRENbV2445oQuKpcMMoL0+sNwvRj5fX45igJ04fCkdI66XdH8PxZCjJwHAzeZbzRUKwtZowX7rnuKnIZDwJ+AcotrsW+/Gq8ueuC6t3GvDD9Kl8PAGKxNhKmDw5eMDrWW4uGNjiMYHTz0iSsy8jDmgzRU8OMG7V+VywJv7EAADcXJzx1U6yqjWJLQgaOg8HXMpk7MQgZZ6vMuoxp8hmYX82KwL78aodwG/OarTCDgXOushHfU3uPQeHoNZQenhUpGTgUDh88zLhJivFHbnEdOrv1eHB6OA4U1RrpuQjzkAbHwTBqsmlwGde3dlGTzWGw/0JvwaiaYdl35Ybmf2TcDJ20lDjMjBarYK/6/qzDNN38587z0u+O2KB2uMyI8kdybACyC2sxSiv6I9ak50le0xlR/na+QnlDHhwHxLSWydGyeoeYZC3J+sx8fMp1FX/q5liH0KH815wY6T5pJz487p8WhoNFdQ7h+QPE78rmXLEab2KMP5JjAx3iu2IJzHn+vjpcTvP1ICEPjoOSlhIHluvj4kQL1VDgBaMBXm4AgPmTQxyi6eaqHb1TxImhcai4t2BUjfBNNpMMXmNqsjk80lLiwJIznTRkGA4Wqxo4dXV1WLRoEXx8fODj44NFixahvr6+z/O7urrw+9//HlOmTIGXlxdCQ0PxyCOP4NKlS0bn3XTTTdBoNEY/CxcutOatqI51GXlggahuPS1UQ4EXjLq5iF+h0tpWaeLOKqhRZar4+sx8bMoqBgBMDPGmFPFhsD4zH18dLgcgbiyWpcSp9j3khekhPqJuiyqmDw9W+RoQU8XVOF6sgVVDVA8//DDKy8vxww8/AACWLl2KRYsW4bvvvjN7fmtrK44cOYI///nPuPbaa1FXV4dly5bh7rvvxqFDh4zOXbJkCV555RXpbw8PD+vdiMpYn5kvCf40mp56HADtDAaDObexmiuM8pkcN40fg93nryDSn1LEhworELl8bhze3F2Azm497k8Ig5NB+K+2DEZemB7q4w4AOHOpEdtPVqjuO2JN2Dxz97Wh+Pb4JYz11tJ3bpBYzcA5e/YsfvjhB+Tk5GDWrFkAgPfeew9JSUk4f/48xo8f3+s5Pj4+SE9PNzr2+uuvY+bMmSgtLUVERIR03NPTE8HBwda6fFXCL1QLZ4Rjc24ZQrzdsSJ1PA4V19GXZojwNT7+78dzqk0V53fiUQFeAK4gknbiw0aj0SDczwMFV1pQWttq78uxKqYV08m4GRp8OPzJm2Px7fFL6OjWS95TShXvH6uFqLKzs+Hj4yMZNwCQmJgIHx8fZGVlDfp1GhoaoNFo4Ovra3T8s88+Q2BgIK6++mo8//zzaGpq6vM1Ojo60NjYaPTjiPAL1SxDTJxcxiPjgYRwAOquMMr3LtvDepddaabeZUNk89IkaWHSG75nH/5cJL2PavLe8Cy+IVr6nYTpQ4MPh//neAUAMev10eQoVYfDLYXVPDiVlZUICgrqdTwoKAiVlZWDeo329na88MILePjhh+Ht7S0d/9WvfoXo6GgEBwfj1KlTWLlyJY4fP97L+8NYtWoVXn755eHdiIrgd1OCIE6wze3dDpOqag1yi2ul39VcYdR0J55JvcuGhen7mOEA7+PfvqfeZcPFNBzu6eaM1k4d/v7DOVWGwy2NRmAr3SB56aWXBjQWcnNzsXPnTnz00Uc4f/680WNxcXFYvHgxXnjhhX5fo6urCw8++CBKS0uxe/duIwPHlMOHD2P69Ok4fPgwpk2b1uvxjo4OdHR0SH83NjYiPDwcDQ0N/b6uWuG1I4A6wyrWxrTCqJMGeOaWOKzLzJfqU6jNq6HXC4j5ww4A4k48/9Xb7XxFyiX2Dzug0wvQaICiVXfY+3IsDl8xnc0114T5YO7EsVidnofEGH/VeqysBc3bIo2NjfDx8RnU+j3kENXTTz+Ns2fP9vszefJkBAcH4/Lly72ef+XKFYwdO7bf/6OrqwsPPfQQioqKkJ6ePuBNTJs2Da6ursjPN68s12q18Pb2NvpxZChFfOTwFUbdXZ2gF4B7pl4luY15z45aWPV9795lxNBZn5kvhYIFlWbE8E02b4wLBABEUJPNEcGnijtraN4eDEMOUQUGBiIwMHDA85KSktDQ0ICDBw9i5syZAIADBw6goaEBycnJfT6PGTf5+fnYtWsXAgIG7s9y+vRpdHV1ISQkZPA34sCsz8zvlSJOX5ahwSqIZhXUIMDLDe1dnXj9p3zVVRjld+Lv7RN7l0UFeOK+aWGqzPyxNiyT6rHkSGzKKoGbodkmQ6cXVOH5M9dks6qpHf85UUFNNocJnyquE2jeHgxW0+BMnDgRt912G5YsWYJ33nkHgJgmfueddxplUE2YMAGrVq3Cvffei+7ubjzwwAM4cuQI/vOf/0Cn00l6HX9/f7i5uaGgoACfffYZbr/9dgQGBuLMmTN47rnnMHXqVFx//fXWuh3FY85lDPRU4KWFamiYSxX/+shF1bmN+d5lqZOCkH6mChEBXtLj1Lts8KzPzEdOoejZ83Z3BSDqtn43p6cK9goVGDcM04rpB4vqVPf9sBXMML7t6mD8cLoS4X4eqjSMLY1VC/199tlnmDJlCubNm4d58+bhmmuuwSeffGJ0zvnz59HQ0AAAKC8vx7fffovy8nJcd911CAkJkX5Y5pWbmxsyMzNx6623Yvz48UhLS8O8efOQkZEBZ2dna96OouFdxr9OjAQA+Hm6QusivmfkMh4eaq8wyvcua2jtMvzbSb3LhoFOL0jv2fqfLki9herbOgGIbQzUOH4YFA4fHrxh7OspGsasJAWb0ymTyjxWLfTn7++PTz/9tN9zeI1zVFQUBtI8h4eHY8+ePRa5PkeCdxk3tIoTqtbFWVqoAHIZDwdzFUbVNomb7sSPlzfQTnwYmO6w2fv5xcEy1b6ffMsSCocPD2YYAz1j5lJDG7r1egDqNIwtxZCzqNTAUFTYaoOU+JaDvZf3T7sKW49chJ+nK+pau1T7nka/sB0CxJ34hb9SBtVIiVm5HXpBFIwWrFLf+8nPNR6uznhiTgzWZOSr9vthC9Zl5ElV6AHHnL+tmkVFKBu1h1RsBV9hdNlccXfV0qHDsrlxqmy4Sb3LLIs5waha4Jts3jM1FAAQGeCJZ+fGU5PNEfLs3HjKgB0CVg1REfLDEUIqtoCvMLr1SDncnJ3QqdPj/mlhOFgkppAnxgycAShneGG6Ue+ym8eRMH0EMMHondeE4D8nKhDs7a4qwShfMf2aq3zxzdFLiA70oorpFoAyYIcGGTgOBPM6jNK6oLmjGwtnhFP/qWFimkXl7+WG2pZOrM3IU02FUT6DasGMcGzJLUOojwdcnEXHL2VQDR1jwagbAKC9WycJRgHlZ1Lx1ZpbO7sBANXNHVQxfYSwuWZGlB9yi+twXbgPzd8DQAaOg8B2jc/cMg6v/3QBAPA/t01AqK8H7cZHgGnp/a0qShXnhel1LaIwnRk9JEwfHuYEo/WtXWjv0gFQj2DU9HuRW0wp4iOBD4n/4rpQ5BbXYbS7KzXdHAAycBwMVnTL290FfoaUQ2JkpKXEYW1GHvSC+nRNphlUpbWttFCNgL4yqTbsLlDd+5qWEifdH+lFRgYfEg/z8wAAFNe04JPFs5BTWKOKkLg1IJGxg8A6GX+SXQIAiA70wus/XVB9J2NbYE7XpCaMSsTTQmUx+JYpanxfzaWIE8NjeWo8Pl+SiBWp8fjyUDkA4GJdG9akqyckbg3Ig+NApKXE4WBRLfZfqMbJiw1Uz8QCsNDfAwlh+Nfhcvh5uqpKMAqYZPyQsNFi8IJRtbyvvDB9ncGg8XJzxtIbYygUbgHSUuIgCALWZIjfyXWZlHbfH+TBcTCu8hXdm3oBcHN2oi/GCDBXYbS5oxvLDK55NVQYZeEpV2fxPh5LjqI0XwvA3tfZhkaU44NHq+J95Sum33MdSxH3gkYjjh+qmD5yKFV88JCB42Dsv1ANQJyIOnV6mmxGAF96//19RXB20qBLJ6CpXcwcUbpgdOG72VidnoelN8agSyfASQP84faJkrBx4bvZ9r5ERcILRn81S2ybonVxkt5XJddQ4lt71Bkqpnfr9NTaw4KYSxUnzEMhKgeAdxtfrG8DAHz9u2TsybtCbuMR0JdgdOPPRapyG7OFKszPE24utCcaKbxgdFzQKABAUXULnrllnCoEo6bC9LyqZlV9H+wJC4nPivbHgaJaXBPmo7qQuCWh2coB4N3GjKjA3h2hieGTlhIHjcqEuEyY/pVB1BhlKNZGwvSRwQtGPzaI/pvau/HaD+dUIxhVu4DaHpiroTTa3YWabvYDGTgOAO82BgB/Lzd8lFVMbmMLsj4zH4KJEFcNpKXEYUaUHwBgf/4VKtZmQdJS4oyK+r29p1A17605ATUxMviQ+I+nKwEAxdWt0uNKD4lbA2q26UDNNp/+7Aj+c7ICGgACHLNRmzVgbuO5E4OQcbYK0QGeKKppNSqGp2S38ROfHMYPhgnVzdkJea/Ot/MVqQvWxNTZSYMCBTcx5UPhq9PzpHnmv26MwTt7C5EY409ePwvxt+/P4u09hdLfjjSXU7NNwiwTQ8XBIIAyqCyFObcxNBpVuY0PlYj350LCdIujJk8HHwp/LDkSAoBRWhd4ujkDoFC4Jfn9bROk312dKQTYFyQydiC2n6wAADhrehYq+mKMDHOl98tqW6E3hPyU6jZmu3FBEFDdLIqM01fMwXfHL5Ew3UIwz9+NcYHYm1+N+LGjFC0YNWrt0SpWTPd0c8aajHxq7WFhWLsdAOjSqaOGkjUgA0fl8G7jM5caAQBrF16HouoWWqgsAL8AsQJc3XoBaxVegItvtMn+ZiXiAWq0OVLMef7cuFRxQJlNN00zqKqaOhT9PZAjzDAeHzwa5yubMDsuUNGGsTWhEJXK4d3GHq6iqziaMqisgpoKcJkK08P9PPDW7gISplsIXjD67fFLAETBKJNEKtXzBxi39lBbbzZ7wxvGrJfgVb4eqgqJWxLy4Kgc3m3cZuhY/MOpSryx6wK5jS2MuQJcSp7cNy9NwuMf5SLjbBVKalspg8qC8Dvsbp0e63+6gOaObimco+T32FxvNiXfj5wwFxIvqm5BqKFCvZINY2tABo4DsHlpEv6w7SQ+P1AKAJJxQ18Ey8Hc8tOj/HCouA5Tw32lCUjJ73PMmFHA2SoI1NrDaqyYNx7rDZoKpXv+2PdgtLsLmtq7sXBGuCq+B3KBN4wrGtrwxcEyHCiqxYGiWprTzUAhKgdhVnRPuIEWKsvCl95/YFoYAMDbw1UVpfczz14GQK09rAn/niq59D5r7ZF2yzg0d4jtSv771vHU2sNKUCbVwJAHx0HYfLAMgBgTpwwqy8KX3mfNTItrWvDRb2cqsvQ+L0wvuNICAPjgsRk4XlZPwnQLwwSj14T54ER5A2ZG+SleMFrf1gVBAEZrXeDv5Wbvy1EtrAo2QJlUfUEGjorhF6rswhoAwPO3jke3TqCFyoKwBYjPHimva8Oa9DxFlt7nM6icnTTQ6QVEB3jheFk9AMqgshTmBKOBo7WKzaQyzaCKCvTC6z9dIO2WFWCGcYiPOyoa2nHnNSGKN4ytARk4KoZfqIK93VHZ2I7oAC/kVzUDoIXK0qSlxEmp4jq9gHUKTRXnhek6vQAXJw2+PlIupb4DJEy3BOYFo62YECwW5FSiYDQtJQ6HimuxN78apy814OTFBkV+B+SMcYkBV1Q0tGNiiDfix45WpGFsTcjAUTH8QlXfJhZryyqowSc5JbRQWYln58ZjbYaYTaVkwejmpUl47svj2HqkXBV1feQIv8OubenEpqxinK1oxNmKRkW/1yE+YphWT8J0q2DOMC6ubkG4vycAZRrG1oIMHJWzeWkS/v7DOWzYXQAAknFDXwDroKZU8evCfbD1iNhJnBYq6/KH2ydiU1YxAOULRvdfuALAWJiu5PuRG7xhfK6yCTtOVuBfh8upv6AZyMBxAOZOGisZOLRQWQ8WF0+M8UdOYS0mX+Wt6Lj410cuAiBhui14e0+B9LsSBaO83u9ifTsA4N9PXY+fzlWR3s+K/G5OLHacrKD+gn1ABo4D8I6h66wGtFBZCz4u7m8ove/p6qI4wSi/UB01iIr/eu8UVDV10EJlJZhhHBPohcLqFtwyYYziDGPT1h6A+YrpNO9Ylh9PV0q/09zeGzJwVAq/ULEvwa8TIzFmtJYWKitgLi5ecKUZN8QFAlBOXJxfqFixttigUahq6gBAC5WlMTKMvdxQWN2CCH8vrEj1U5RhzOv9ACDExx0b9xdJGVQA6f0sDTOMR2ld0NzRjYUzwxVnGFsbMnBUCr9QxY7xQsGVFsSO8UJju1iAixYqy8JPJJ3deryx6wJqWjoVlyLLL1RNhrGSefYy3t5TSAuVFejLMPb3EgtzKsUwBkS939KPD2HnmcuobGhX3NhXEsaGsSuaO7qREOGHUB8PRRnG1oYMHJXCL1R1rV0AgBMXG/D1kYu0UFmZ528djzd2Kbf0/ualSfjTN6fwaY5YSIwZN0q7DyXAG8YX69uwJbcM+/KrsS+/WpHveWzQKODMZdKEWBlzhnFhdYvUUFlJhrE1sWqrhrq6OixatAg+Pj7w8fHBokWLUF9f3+9zHnvsMWg0GqOfxMREo3M6OjrwzDPPIDAwEF5eXrj77rtRXl5uxTtRJpuXJuHZlDjUtogp4sy4SUuJQ1pKnMO7L62FGkrvU2sP2/M/t46XfldqJlW6IRxOrT2sy3JuHr95/BgAolCdec1IfiBiVQPn4YcfxrFjx/DDDz/ghx9+wLFjx7Bo0aIBn3fbbbehoqJC+tmxY4fR48uWLcO2bduwefNm7N+/H83Nzbjzzjuh0+msdSuK5RfXhUq/00JlfVg/nmvDfAAAMwyl99dn5mN9Zr5ielKxxqx8BhVhXZjHDOjJpFICa7jxfcHQ2uPDx2ZQDyob8dsbogGAGuKawWohqrNnz+KHH35ATk4OZs2aBQB47733kJSUhPPnz2P8+PF9Pler1SI4ONjsYw0NDdi4cSM++eQTzJ07FwDw6aefIjw8HBkZGbj11lstfzMKZp1hkqQMKutjVHrf0IPH38tNMZlU5lp7/PetE9Cl05Mw3cqYlt6/Y4pySu/zej8njVjgL2aMF45Raw+bsCfvivQ7zfHGWM3Ayc7Oho+Pj2TcAEBiYiJ8fHyQlZXVr4Gze/duBAUFwdfXF3PmzMGrr76KoKAgAMDhw4fR1dWFefPmSeeHhoZi8uTJyMrKMmvgdHR0oKOjQ/q7sbHRErcoW/iF6t/HLgEA7rw2FHFBo2ihsiJm4+JXWnB1qOjNkXtcnF+ogkZrUdXUgdgxXjhX2QSAFiprYZpJVdHQjvixozE+WBml93m9n14A3F2dsPVwOdZkUGsPa8MMYxcnDbr1An6THKUYw9gWWM3AqayslIwSnqCgIFRWVpp5hsj8+fPx4IMPIjIyEkVFRfjzn/+MW265BYcPH4ZWq0VlZSXc3Nzg5+dn9LyxY8f2+bqrVq3Cyy+/PLIbUhD8QnV1qDdOX2pE7BiqSWFt+Imkoa0LG/cXIb+qWTHZJMbC9J7WHpuyimmhsiLmBaPNiB0zCoD8DWNA1Pst23wU3xy7hI4uvWTcyP26lYypx/hKUweSxwXCz8tNEYaxLRiygfPSSy8NaCzk5uYCADQaTa/HBEEwe5yxYMEC6ffJkydj+vTpiIyMxPbt23Hffff1+bz+XnflypVYsWKF9HdjYyPCw8P7vQclY7RQGQTGeZebseNkBS1UNuKPt0/Exv1FAJQlGN28NAmvbj+D9/aJ186MG6VcvxLhDeMLVc349vglfHvskuJK718d6oNvDNdNWhDrY95j3Cw9rgTD2NoM2cB5+umnsXDhwn7PiYqKwokTJ3D58uVej125cgVjx44d9P8XEhKCyMhI5OeLWpLg4GB0dnairq7OyItTVVWF5ORks6+h1Wqh1WoH/X+qgc1Lk7A+M18a+My4cfQBbwvWpOcht7hW+psvvb8+M1/2buObxgdJBg4tVLYlLSUO3x5XjpHAwuHidRu39nj4vRzMiPKX9VhXMvz7ml1QjezCWrz2wznoBWUZxtZkyFlUgYGBmDBhQr8/7u7uSEpKQkNDAw4ePCg998CBA2hoaOjTEDFHTU0NysrKEBISAgBISEiAq6sr0tPTpXMqKipw6tSpIb2uI/DrxEjpdyV5EZRObnEtsgpqEGAQGs+JD8Tq9Dw8/F4OVnP6KLmycb+htQdlUNmc745fkn5XwnvPwuEPv5eDkxdFbePqh65DcmwAsgpqjAx9wno8PEuc66mDuzFWSxOfOHEibrvtNixZsgQ5OTnIycnBkiVLcOeddxoJjCdMmIBt27YBAJqbm/H8888jOzsbxcXF2L17N+666y4EBgbi3nvvBQD4+Phg8eLFeO6555CZmYmjR4/i17/+NaZMmSJlVREir/1wTvpdSWmnSmZ9Zj6yCmqQHBuAGkN4MNTXQ5rwk2MDZDn58Km+P50TszKWzo6hVF8bsvDdbKzLzIefpysA4IGEMNmXGEhLiZPGtquzaLgfNBj47DjNO9bnQFGN9LsSDGNbYdVKxp999hnS0tKkjKe7774bb7zxhtE558+fR0NDAwDA2dkZJ0+exMcff4z6+nqEhITg5ptvxpYtWzB69GjpOWvWrIGLiwseeughtLW1ISUlBZs2bYKzs7M1b0cR8BlUW3LLAACz4wIxI8qfMqhsAIuLp6XE4XefHsb3pyqx+WAZBADJsQGYEeU/4GvYA16YHunviZLaVsSOGYXKRrEzNAnTrYuRYNTTDXWtXbg2zAcR/p6yF4zOiPJHt06Pg8V1AMQaSuw7wEKyhPVgmVSM382JpUwqA1Y1cPz9/fHpp5/2e44g9Ax+Dw8P/PjjjwO+rru7O15//XW8/vrrI75GtcEvVNMj/XCopE7KxgBoobI2/ETyu5ti8f2pSklP8fmSxL6faGd4YXqtIYPqcGkdtuSWkTDdBpjvSdUCf0OYU86C0eWp8Zgzfgzu25AFwDhEItdrVgu8Ycya494yMQgebs6yN4xtAfWiUhlGC5UhRFJa20KpvnZg5+kekb0SCnBtXpqEf+48j9d/EvtoMeNGztesFnjD+NTFBuw8cxkfZRdDUIhg9K3d4pihgqK2xaxhXEWZVAyNwLtQHITGxkb4+PigoaEB3t7e9r4cq8BnUAHKmCTVBHMbe7u7oLG9Gw9ND8OXh8qNjEw5uo1Pljfgrjf2AxB34nmvzrfzFTkeh0vqcP9bPd4QuX4GfDiczTW/uT4Kfp5iHZbEGH8Kh9uQe9/8GUfL6qVq0mqd84eyflu1FxVhP5beGCP9ThlUtoV3G7NMqmvCfCXBrtwyqZjAGADe3GW8E3/4vRxZilvVypr0PLz2w1npb14wKjehMQuHr07PQ1SAJwAgLqhHK8nC4YRtuD8hDABlUvFQiEpF8DUp/t/2M9LxLp1ANSlsiDm3cf7lJgSMEmsxyc1tzBaqnMIaZBWI2RiLkiJxoapZ+puwDbnFtThYVAc3Zyd06vRYOCPc6LORk56CD4fXNIvh8OPl9aTbsjFs3i+va5WO8YaxXL3FtoAMHBVhbqGaHukHNxcnWqhsiDk9xcfZJbKtTJuWEieNGT9PV9S1dqG8rrVXqq/crltt8CUG2Pf1unBflNa2yrbEwOalSfi/H8/hzV0FAEi3ZQ/4xBLG0zePI5ExKESlKviaFFf5ugMAOrr1VJPCjjx58zgAkH1l2hlR/kiODUBdaxcA4KdzV7AiNR6fL0nEitR42onbAOb5+3xJIqZF+AIA/rDtpPT9lWuJgdRJwdLvch7jjoCnm1gqhdXgcnTIg6My2CTIdoAnLzZQTQo7scbgTWPw2SVya9mwPDUerZ3dmPS/YpkGXrdFC5Zt4MfCQ9PDcaS0XtJTyK3EAB8O32BGt0XhcNthLiT+xcFSChOCDBzVwSaVqBe2AwBcnGihshe5xbU4UFQLNxcndHbrsUDGegoAeHV7j7iV759F2J5jZfXS73JMuzYXDn80OQp5l5soHG5jeENybUYe9ILYD0xO48VeUIhKhazeeV76vVtPLRrsAa+n6OzWAwCuDfOVXcsGvkXDZwdKAYgiaGrRYB/WGPo6bTZUIQeAJ2+Klfo9ySWLig+H+3qIrSXKanvrtgjbsT4zH8xZoxdA7z/Ig6Ma+JoU6w2F2nw9XfGb5Chq0WAH+JYN97/1Mw6X1ONP35yEXpBXywajytdRfjhUXGc21VcOxpgjkMv1cSq80oLKxnakTAzCsbJ62XlGTMPhmeeqKBxuJ1jdrQUzwrEltwyjtS7UrgFk4KgGfqGaPzkY35+qRHzQaGg0otFDC5Vt4SeTBdMjcLhEnnoKo8rXhlTfi/Wt+CSnhGL4doA3GiL9xdoyb+8ukKXQeHlqPFo6unH1i6Tbsifm6m41dXTjqZtjHT6TigwclcAvVNXNHQCA9m4dVqfn0UJlZ46W1Um/y1FPsXlpklHla5ZBJadrdBSYYcx/Hulnq2T7eby6g3Rb9sZUZOzl5oyWTp2USSW3ulu2hFo1qKxVA7VokBemnX6fvCkWG3YXyK5lg2kGVf6rt9v5iojYP+yATi9AowGKVt1h78uRMNeiISkmAEmxAdSiwc44wvxPrRocGH4w8xlUhO3hXcejtKKzNGVikGxaNvAtGkwzqOQkaHU0mNCYeVwFTjAqh3YNfIuG6VF+AIC4saOkx6lFg/1IS4kDm1Iok4pCVKqAr0nxT5MMKqpJYT/Mt2yQT6dfc6m+s6L94eykkZ2g1ZFgQuOZUX44WCyGN+VUXsCcbqu8rg0fZ5Nuy56sSc9DbnFtr0wqOdbdshVk4KgAcwuVv5cbJgSPpoXKjvCTye7zVThSWo8/bDspm06/fIuGUF93XKpvR3uXDsfLG6hFg50wbdcwSuuC5o5uTL7KW1blBXrrtuSrE3IUmGE8+SpvnLrYiFGGTCq5GMb2gEJUKoCvSTFujOgq9nR1ppoUMmLhzAgA8uv0y1o0XKpvBwAcL2+gFg12hG/XsCI1Hs0d3QCAUxcbZZdF9Zvro6Tf+QwqwvbwhvGpi40AgOaObsyM8pOVYWxryIOjEkxrUpTXt1FNChnAwoeXG9ulY3Lq9EuVr+UFPxbSUuKMKtPKobwAHw7/f2Z0WxQOtw983S3es3awuE52hrEtIQNHJbBJJXrldggCpEkIoIXKnvD1iTQaUTC6dHaM3etT8AvV3384Jx0n3ZY8kKuewlw4/JYJQWjv0lE43I6YGsZrMvKkdUAOhrG9IANHBfBpmyzpX8e1aLC3l4AQ8fN0Q21LJ64Y6hTZE3ML1VW+HogM8KSFSgYwPcU1YT44Ud4ANxcnWegpeN1W0Ggtqpo60NzeJXkKSLdlX5hhbLoO2Nswthdk4KgA3ksAiJ6Cp24aZ3cvAWE+k2rb0Yt2zzbhF6qoAE8U17RC6+LUS7dFC5XtMRUaO2mAzm49pkX4ykJPYRoOP1hcR+FwmcAM47igUcivakaIj7ssDGN7QQaOCokK8IKbC+nH5QC/W1qXkQ+dIMimPoXpQlVY3UILlQzoS09xpLReFnqK5anx0OsFxPxhBwBq0SAXTA1jAGho60JSjL8sDGN7QJWMVVDJmIWoDhXXYm9+NZw0kFKRAQpR2RvmNuZDP6aGhD0/n+gXtkOAKDC+8FeqYCw3YlZuh14AnDUaFKyy3+fD67Ze/u40Pvy5WHqMGV40z9gP/vNZm5GHtRk9mbNq+nyGsn6TB0cFsEG7bPNRAPJLRXZ0mHEzPdIPh0rqoIF9C7fxE+Ga9DywHQ4JjOWFqdBYJ9hXT2FOt3VNmA9GaV1ItyUD+LGwbG481mXkSxsXRxUaUxxD4fDl9vflVwMQB3SnTk/l9mUA7zY+VFIHD1dnCBAXBnu5jdlC9fB7OVhnGDtebs6SKzu3uHaAVyBsATOMJ4WKu1QfD1fpc7NHmw++3laYrwcAQK8XqN6WzGCtPviNi5xafdgSMnAUDlusFr6TLXWP3ff7m6UJhxYr+2JauK2tSwcAOGGoFmwPPQW/UMUFiYUhfTxckV1YSwuVTOAN4zOXxMJtDW1dmBlt38JtrDBkeX0bAODUpUYqDCkzmGEcHegJAIgO9LKrYWxPKESlcPhsGADw83TFl7lllA0jE+RauM1UYHypoZ0ExjKiz8JtRfYt3EaFIeWNOaFxW6dO+tvRhMYkMlaJyPg/Jy6h4EoLNAAEyEvESshXaMwXhiwggbFssffnZFoYcsPuAukxNQlYlQ7/Of3jx/N4Y9cF6TG1fE4kMnYwlqfGo6GtCwVXWiDAWGDsSNa6nDEt3Ka1Y+E2KgypHORSuI0KQyoDfiw8f+t4ycBxVKExaXAUDC8wTj9zGYA4EZHAWF7wbuMT5Q1w0gAd3XokRNqncBtbrPgWEs/cMk465kgxernDDON4g1Yq2NvdLnoKXrcVHSBqO8wVhiTkARMaMxxVaEwGjoJhC9Uv383GRYPo7z/P3EACY5lhKjRm8pbDJfIo3BYd4AVXZ5oK5AZvGOdVNQMA6ts67Va4jQmMi2paAfQUhiSBsfxghnG4n5jtNjFktEMKja06q9XV1WHRokXw8fGBj48PFi1ahPr6+n6fo9FozP783//9n3TOTTfd1OvxhQsXWvNWZAnbVWUXioaMm7MTfjhVSbsqmbHcoLVhuyY2tzhrRLfx8tR4m+6qmMF1w7hAAEBxTQtWp+dhRWo8LVQygjeMl80VDZn2Lr2U7WZLw5iFNT9fkgi2NDKBMen85AVvGJfViRtfQYBDCo2tqsF5+OGHUV5ejh9++AEAsHTpUixatAjfffddn8+pqKgw+vv777/H4sWLcf/99xsdX7JkCV555RXpbw8PDwteuXKYEeWPmuZOnL/chC6dHusy8ykbRqaY9gxjhdsASAaGteFFiE99dgRAT2FIgPQ3coJ9DuwzYwkEfIdoWxkXbOxmXajuVRjSEXscyRk+A+//bT+D9/cV4VxlEwDIwmNsS6xm4Jw9exY//PADcnJyMGvWLADAe++9h6SkJJw/fx7jx483+7zg4GCjv//973/j5ptvRkxMjNFxT0/PXuc6EmzSW54aj269HucvN0kCY/Y4LVTyxtPN2aghqi12VbyRtS//CoCewpC2MrKIodHLMNbb3jA2LUcROMoNcUGjHM4joAR4w3i0tmeJd7GDYWxvrBaiys7Oho+Pj2TcAEBiYiJ8fHyQlZU1qNe4fPkytm/fjsWLF/d67LPPPkNgYCCuvvpqPP/882hqaurzdTo6OtDY2Gj0o3TYpLc+Mx//OV4hHWMLlaPEWJUCq2WyIjUeabeMAwC0dupsfh1pKXFYkRqP1el5aGzvBgAsvTFmgGcRciLU0CFaGk82MC5Y2IMVj6tp6aTCkDLH2UmDNVw/KiY0ZnORI6wRVvPgVFZWIigoqNfxoKAgVFZWDuo1PvroI4wePRr33Xef0fFf/epXiI6ORnBwME6dOoWVK1fi+PHjSE9PN/s6q1atwssvvzz0m5AxbFLjd3YLZ4TjswOl9rokoh+Y21inF+Di7CSFG5iOge3K7bGr2rC7QPICsPFEO3J5wBvGtS0d2JRVgksN7Ta9hjXpeThQJIahympbUVTdCsEQ1kyMCYBeECgUrgAmhXjb3GNsb4bswXnppZf6FAKzn0OHDgEQBcOmCIJg9rg5PvjgA/zqV7+Cu7u70fElS5Zg7ty5mDx5MhYuXIh//etfyMjIwJEjR8y+zsqVK9HQ0CD9lJWVDfGulcFnB0oloSjz7hDygAmNmeeN1zEAPR45a+6qWFkBnV5AcmyAdJzX35DIWF7wn4mfp5t03NVZIx23tkDd2UmDHEMiw67zVQCMw5rJsYGqD3UoDd4w/sV1oQCAsxXKj1wMlSF7cJ5++ukBM5aioqJw4sQJXL58uddjV65cwdixYwf8f/bt24fz589jy5YtA547bdo0uLq6Ij8/H9OmTev1uFarhVarHfB1lALT3+j0Am6fHIwdp0SPGC1UyiMqwNNmuypmRK1IjcflxnbpGK+/cYRdnZJghgPfrgEAunTGhrE1dTjmvMW/vT4a7+4rtNr/SYwMfg0I9hYdBAJEw/iZW+zrMbYlQzZwAgMDERgYOOB5SUlJaGhowMGDBzFz5kwAwIEDB9DQ0IDk5OQBn79x40YkJCTg2muvHfDc06dPo6urCyEhIQPfgArgJ7VKw0LlpAEtVDKH31VVNLTji4OlKDbUFLEF5haq+6eF4ctD6vRoqplrw3zsGm54d18hhTVlDG8Yv7O3xxC1pWEsB6ymwZk4cSJuu+02LFmyBO+88w4AMU38zjvvNMqgmjBhAlatWoV7771XOtbY2IivvvoK//znP3u9bkFBAT777DPcfvvtCAwMxJkzZ/Dcc89h6tSpuP766611O7LC3EKVOikYP54enLaJsA98+mZ7lw5fHBT1UvyuytZ8eaiMFiqZwxvG5yubsP1kBU6UN9j0GnR6ATfFj8HuPDHzjm8Hwx4n5M+NcYEOpcOxah2czz77DGlpaZg3bx4A4O6778Ybb7xhdM758+fR0GD8Zd28eTMEQcAvf/nLXq/p5uaGzMxMrFu3Ds3NzQgPD8cdd9yBF198Ec7Ozta7GZnz4+lKWqhkDp++yVeZZrsqVvDPmm5jnV7A3deG4tvjlwDQQqUEeMO4pKYF209W9Ao3WAu+HMW8NXsAiAUqWTsYNTRvVCu8YXygqAY/X6jB/gvV9r4sm2JVA8ff3x+ffvppv+eYa2a+dOlSLF261Oz54eHh2LNnj0WuT8no9AIWJUbik5wSALRQKQlWRj3E2x0Vje2YGu5r9cab/EL14NtimQYW1qSFSt7whvHBop7GlrYwjPkmm3mXxXYRnyyeiTd2XaAmmzKHN4z35/vh5ws1UlHPp28Z5xBrBHUTVxj8QrV4Uy4AQANaqJQCX0adLRA6QbB6GXV+ocotrgMA/O3+a/DN0Yu0UCmE3OJaZBfWws/TFXWtXZgTH2h1w9i0wJ+TBsgqqOnVDoa8xfKDN4yzC3s8N506vfS42oXG1GFPYbCF6uH3cpB5TkzZfIbr9EsNNuUN31/o8RuiAQAnyhukBcNaZdT5btCsSsOZS43Ut0wh8IZxXWsXAMDTzcUm/YVmRPlj/Fixm7kgAG/sukBNNhVEbnEtDhbVwdNNlHDceU2IwzTeJA+OwuB3VFoXJ3R061Fe10o7KoVgVEbd3TZl1JnXb0aUP5rau3Hyoqh525RVLBlViTEBtFDJGD7tt6GtC6cvNeJ7Q3kI9hlaa9wsT41Ha2c3zl9upnYwCsOcxzhotLvDNN4kD46CYIXaZkT5Y3qkHzq6RVfj10cuSpMc7aiUgS3LqPNFBO+delXPcY0GWQU1UvNNWqzkC18o8vSlnoJtrs6iYWyNQpF8O5jtJ6gdjBJhhvGMKH/EBYleuA9/LjLyGFu7UKQ9IQ+OBeA7NJtiyV0VX7tg8Q3ROFQiainYQpUYo25rXM3EjvGyWvomX1YgwEushqtBj/aHxoxyMNXEdOmMO3pba9wwHkmKxIc/F1vs/yCsC18PJ79KFImzDLzPlyQaZVpZAluthYOFPDgWgN/p8Fh6N843SvzLf84AoIVKibBxkRjjj8lXeQMACq609DrHkrsqpsGpaekEIE5ypL1RHizkEOIjVqfVAFYJNawxM58BwIc/i2HNxBh/agejINJS4pAU06PvY4axpQvD2motHCzkwbEApjudtJQ44+7RFt5V8Ts404WKjBz5w9zGgPHumNU1ySqoRk5hrUV2VWu4SYXPlnJ11kiNEqlukjLgDeMAL61UD4d5cNmiYoldMluoEmP8ccO4AOy/II4d9n+tSI1HcmwghcMVwvrMfGQX1sLfyw21LZ1WM4xtuRYOBjJwLERaShwa2rqwOj0PazPyoBcsG2qghUo98IuPabghp7BGMm4s8TnyC1XsGC8UXGmBxvB/sUmHFipl0Jdh3FNmwHKGMb9Q+Xi4AgA0GvIWKxHeMNa6OGNP3hWrGcaAOHY6u0Wd1rqMfOgEwW5VkylEZSHWpOehy1BfQC+Ihgf7QC0RbmALVVZBNSaGjJaOs4UqOTaQBMYKg4Ubwv08AFgn3MDCmjmFtVIYbEaUX69zSGAsf5b3sUjcdU0IsgosaxgD4rhIjPFHQ5uYli4IFNZUIswwTo4NxB5Dqw3A2DC2RPiID2smRPpJ/wefdWdryINjIZydNPg4u0T6u0snSB+2JURc5gR/V4d6G2VU0K5KOfC7qsgAL2zJLbPqrornYHEdtfVQKLy7/6dzl3GsrAHbT1ZY9P/gvcU5hT11tdycnchbrEB4oTHPwhnh2JwrNtq1hGHMNuEAsCdPrNFm2gTa1pCBYyVmRftbLCtmTR/W9elLjUiOpQlHidgi3MDGjU4v4LfXR+EDQ/aLq7PG6BrI66cc+M8s3M8Tx8oaepXfH2m2Ch/WjPD3QGltGzQmCxWFNZUFM4yTYwNwpakD+VXN+OpQufR4TmHNiDdT5jbht10djB2n7NcEmkJUFoDfjceO8QIAHCyq7XXOcF10fHjqyZtipeOsbDqFp5RHX+GGWyaMsVi4ga+NUlbbCgBG+huqf6M8+Ho4353o8dyw8vuWqIfDhzVLa9sAADfFj+l1Do0b5aDT97SDCff3FI8Zwkfs+EjGTF9ZdztOVdo16448OBbA3G6c7/Y70t04bxmzMu2AqPUhwZ9y4Q3ji3VtKKtrw67zV3qdM9ydlbkd1axof+QUUTsPtXHHlBCLeIz78hbvOn+FvMUKhg9T8fNBp05vkRpKvNfvzikh+I8hbGrvrDsycCyALbJiTNPDAUoPVzpmDWPBMoZxXwtVTlEtLVQKhw83tHXpcLS0Ht+f6vHmjCTcwC9UDySE4V+HxTCGvRcqQt7wm6kxo7UA5FGjjQwcC8KyYry0zmjp0PXKihnObryv9HAXJ0oPVzr8OMguqEa2QdBpCcOYX6h+NSsCnx0oFY/TQqV4+HDDvVOvwtHSekmHMz3KT6pqPhz4hSrUpyesae+Fihg5vGGcU1gDvSDKHJbNjZe60s+I8h+yYcxXL+bnMQFAuJ+HXTfhZOBYCH7w8EX42ILCl1MfCvxCNTXCF0dL6wGIvYtI8KcOFr6bjZzCWgSOckN1s3ERLmB4TQ35hepiXZt0nBYq5WOtcAO/UJkWE7X3QkWMHN4wZrBlgx0fjmHM1qicwhrJuAFE46msrg3JsQF224STyNhCsHDD50sSMTO6p86IThCkyWGoE88aLqaeU1grGTcR/h5G55HgT7msz8yXUnFnRoml1HnDeDiCUSb4Y+0ZyjgDh1+oCGWTVVDd52PDSWpgCxXbjDFMFyoaO8pkeWq8kQGjMUwrYgJLz+Z7qOOGidKzCmqkopBAj0b08yWJdkuCIQ+OheB3VQeL6qB1cUJHtx4abnIYapiKTThsJ89gmQ32tIwJy9BfujgAJMb4D/mz5XdU/S1UAI0bpcIbxhqNqN3SQJyHeLHxUOC9fr6erqg3JDTwCxWbvwjlYRplEEw+RjZfDGXc9OX1A+Th9SMPjgXhB1BHt5i2KQjGYaqh7Mh5y5j3CgGQvEWUHq5sWNpvX7vx5NjAIe3Gea9fVkEN/D3dpMf0AhDm50HjRgUwwzjMz0NaqAQA+/LFLLxEQ2PFoYwb3utXz2Vrmi5U5C1WJnyUgTdiNJqeENVQowxy9/qRB8eCsAGUlhKH+9/6GYdL6sXjwwxTMet4BbcrY1iiMBMhD4x24xAXKo0GWD536LtxNuGI2izjeDsAlNe1kY5CBSxPjcf6zHyUc+FHAMgtrjPUHQkYUvVY8vqpH36t4DdUggCjtWkoUQbe6+fn6SqVMZGL148MHAvCBsTCd7NxuKQenm7OaO3UGYWpgMGLRs2FqJw0QGJM74WLUC7MMP7yUJm0YAmC+d34QOPGXO0bBrVnUA98ywbA+PPOKqgZ0mbKdCPl7+mG2tZOAMZePwpPqQN+Q2XuscEaxnIPTwEUorI4/OC5NswHgHGYarAhKuZaNqd6zyqoQRiJRVUDM1r62o0nxwYOedwwo4iHef0oPKV8eG+xufAm024NJrzJ9xBKjg2QjBsG7/Ujj7Gy4Q2YMD/jZJXV6XlGxs1gx41cw1MAeXAsDpt4srh6AICxaBQYeDfOBo/pIGRE+HvioenhtFCpAEvuxs15/Zw1GsyK8Zcmoc+XJFr4Dghbwyc1mNuNM+3WYHbj5PVzHPikBtMNFQBpvRlo3Jh6/UzDU3Lx+pEHx8Iw0aiTxvxu20kzuF4xTOxXXtdmlHoHGHt1aEelfCy1G+/L66cTBPL6qRBL7cbJ6+c4LOcM1hWp8b3ExuV1bdJj/Rmzpl4/voUQIB+vH3lwrACraBzm5yFZyRoASYaFZyAtDrOOZ0T5o7Nbj0MldUaP6wWacNSEpXbj5rx+TLQMkNdPbVhqN05eP8eC31AtfDdbOs6y8fgNlTmxcX/JL+z5LKwO2NfrRx4cK8AGUIShaysgLjLMuGHtFfry4vAdgbWuPR+Rs8ErxBZB8t6oh5HuxnnvTXldGzxcnQH0GDfMewPQuFELprtx3gOjgfFuHBh43JDXzzFgUYbBbKjMrVG898ac189Jo5FKnNh7M0UGjhVgEw+bIEzhGyiaTjp8HZPV6Xn4+YI46Wg04qQT5uchPUaTjnoYym48t7i217hhk45eEDApxBttXTqjxyP8PWUx4RCWhd+N82Fx9imzBcjcYrXGMJZWp+ehtLZVOs6fRuNGnYxkQ8VaPpjz3sitZhIZOFaAHzy8Fwcw7jFkOunwEw4A+Hn2aG+Y+5AtfjTpqAvT3bhp9Wq2G2c7bdNxA/S09KhoMDaQyHujXvjdeFZBDcJ83Y0eZ5o/c4uVs5OY2RluCKWzIcWmlXAaN6plJBsqftyYeoDkkj3FIAPHCvCDx5wXp7S21eykwwYOGyCmwq3k2ACjuCdNOuqC342ba3oXxhWLBMRxY2oUT43w7TVu2C5cLpMOYVmMNlQBXkaPmW6o2GLFG8VldW3w8XCB6X7pwenhtJFSKaYbqqQ+wpumGyrTccM/h5EYEyCbcUMGjhUwHTymXpxyrugfm3QWvCOKvViJ/QAvN5iSGBMgm9gmYXn43bi5HmTldW1Gabtbj5Rj65FyI6P4XEWj0XP4XTiNG3ViuqG6ysSLwzZUbLFi44YZxU/dHIuGtm6j5/AhCNpIqRN+Q5UUGygdN9XtsbG14J1saTOVU2hcaJY9R27jhrKorITppBPu52Fk8ZbWtkoLU1ZBDbzdXXCgSNTmPJsSh3UmO20qle4YmGZLmVasZhVD+Qw9NhEFeWtR1dhhdP6D08MB9Bjbcph0CMvC2jb0VUupvK5NMnRNx83q9DyE+rj3es3EmJ52DwDNOWqEz95cnZ6HpBh/o9ptphsqb3cXNLZ3m20Bw2DjRi4bKat6cF599VUkJyfD09MTvr6+g3qOIAh46aWXEBoaCg8PD9x00004ffq00TkdHR145plnEBgYCC8vL9x9990oLy+3wh0MH1MvDltoGOV1bXDWQDJuGtu74e3ugtXpeXhj14Ver8fcfhRmUDem3cVNvThsvPBx8/K6NmhdnHoZN3w4k7w36sZ03Dx98zijx8vq2syOGy83Z1xqaDc6l99M0bhRN7xhzHtxGO/vKzQybrQuTn0aN3Lz3gBWNnA6Ozvx4IMP4ne/+92gn/P3v/8dq1evxhtvvIHc3FwEBwcjNTUVTU1N0jnLli3Dtm3bsHnzZuzfvx/Nzc248847odPp+nll22M66ZjWotAZ5g1m3DS2d0vP46EJx3FYbmLcZBXU4HdzYo3OYeOEh3WvN4U0W46B6YbKzaX31G5u3LR0Gs+ZLEQux8WKsDyma1S4iV6UjRn2b3/zDBs3clqfrGrgvPzyy1i+fDmmTJkyqPMFQcDatWvxxz/+Effddx8mT56Mjz76CK2trfj8888BAA0NDdi4cSP++c9/Yu7cuZg6dSo+/fRTnDx5EhkZGda8nSFjOun0h7nJRwOacBwRlobJ4t8ebs5Dfg0yih2Pgbx/g0WuixVheUw3VGV1bZgR5Tes12LjZjA982yFrETGRUVFqKysxLx586RjWq0Wc+bMQVZWFgDg8OHD6OrqMjonNDQUkydPls4xpaOjA42NjUY/tmIkkw6bWmjCcSyWp8ZjRpT/sMcNM47IKHYszHn/EqN7F2LrC1OjeEaUP40bB8B0QzU7bsyQni/nzZSsDJzKykoAwNixY42Ojx07VnqssrISbm5u8PPz6/McU1atWgUfHx/pJzw83Ox51sDcpDPYxYomHMdluOOGP5eMYseDX6ySYwOQU1Q7KCOHjGLHZSQbKrmPmyEbOC+99BI0Gk2/P4cOHRrRRWlMGlUKgtDrmCn9nbNy5Uo0NDRIP2VlZSO6vqFiOukMZrGS+8AhrM9Qx425c8kodizYYmVq5PQHGcWEuQ3VQChh3Aw5Tfzpp5/GwoUL+z0nKipqWBcTHBwMQPTShISESMerqqokr05wcDA6OztRV1dn5MWpqqpCcnKy2dfVarXQarXDuiZLsDw1XiqQxA+I/pD7wCGsz1DHDRk3BNB73AwEjRsCMN5QDQYljJshe3ACAwMxYcKEfn/c3XvXVRgM0dHRCA4ORnp6unSss7MTe/bskYyXhIQEuLq6Gp1TUVGBU6dO9WngyAHTnZUp3u69bU05DxzCNvQ3bpJjA8ymkdOYIZanxkMvmN8UmWbKADRuiP7HTF/IfdxYtdBfaWkpamtrUVpaCp1Oh2PHjgEAxo0bh1GjRgEAJkyYgFWrVuHee++FRqPBsmXL8Ne//hVxcXGIi4vDX//6V3h6euLhhx8GAPj4+GDx4sV47rnnEBAQAH9/fzz//POYMmUK5s6da83bGTFsZ6UXBJTVtkKj0SDMzwPJsYFcP5lqsVaFAIT5e8h24BC2g42bkpqWXmMGEGtZfHmojMYMYcSs6N7hTNO5hofGDWFuzADiuAHQa8wA8h43GkEYosk2BB577DF89NFHvY7v2rULN910k3gBGg0+/PBDPPbYYwBELc3LL7+Md955B3V1dZg1axbefPNNTJ48WXp+e3s7/vu//xuff/452trakJKSgg0bNgxaPNzY2AgfHx80NDTA29t7xPdJEARBEIT1Gcr6bVUDR66QgUMQBEEQymMo67es0sQJgiAIgiAsARk4BEEQBEGoDjJwCIIgCIJQHWTgEARBEAShOsjAIQiCIAhCdZCBQxAEQRCE6iADhyAIgiAI1UEGDkEQBEEQqoMMHIIgCIIgVIdVe1HJFVa8ubGx0c5XQhAEQRDEYGHr9mCaMDikgdPU1AQAg+5dRRAEQRCEfGhqaoKPj0+/5zhkLyq9Xo9Lly5h9OjR0Gg0Fn3txsZGhIeHo6ysTJV9rtR+f4D675HuT/mo/R7p/pSPte5REAQ0NTUhNDQUTk79q2wc0oPj5OSEsLAwq/4f3t7eqh24gPrvD1D/PdL9KR+13yPdn/Kxxj0O5LlhkMiYIAiCIAjVQQYOQRAEQRCqgwwcC6PVavHiiy9Cq9Xa+1KsgtrvD1D/PdL9KR+13yPdn/KRwz06pMiYIAiCIAh1Qx4cgiAIgiBUBxk4BEEQBEGoDjJwCIIgCIJQHWTgEARBEAShOsjAGSKvvvoqkpOT4enpCV9fX7PnlJaW4q677oKXlxcCAwORlpaGzs7Ofl+3o6MDzzzzDAIDA+Hl5YW7774b5eXlVriDobF7925oNBqzP7m5uX0+77HHHut1fmJiog2vfPBERUX1utYXXnih3+cIgoCXXnoJoaGh8PDwwE033YTTp0/b6IqHRnFxMRYvXozo6Gh4eHggNjYWL7744oBjUs6f4YYNGxAdHQ13d3ckJCRg3759/Z6/Z88eJCQkwN3dHTExMXj77bdtdKVDZ9WqVZgxYwZGjx6NoKAg3HPPPTh//ny/z+nre3ru3DkbXfXgeemll3pdZ3BwcL/PUdLnB5ifUzQaDZ566imz58v989u7dy/uuusuhIaGQqPR4JtvvjF6fLjz4datWzFp0iRotVpMmjQJ27Zts+h1k4EzRDo7O/Hggw/id7/7ndnHdTod7rjjDrS0tGD//v3YvHkztm7diueee67f1122bBm2bduGzZs3Y//+/Whubsadd94JnU5njdsYNMnJyaioqDD6efzxxxEVFYXp06f3+9zbbrvN6Hk7duyw0VUPnVdeecXoWv/0pz/1e/7f//53rF69Gm+88QZyc3MRHByM1NRUqc+ZnDh37hz0ej3eeecdnD59GmvWrMHbb7+NP/zhDwM+V46f4ZYtW7Bs2TL88Y9/xNGjRzF79mzMnz8fpaWlZs8vKirC7bffjtmzZ+Po0aP4wx/+gLS0NGzdutXGVz449uzZg6eeego5OTlIT09Hd3c35s2bh5aWlgGfe/78eaPPKy4uzgZXPHSuvvpqo+s8efJkn+cq7fMDgNzcXKP7S09PBwA8+OCD/T5Prp9fS0sLrr32WrzxxhtmHx/OfJidnY0FCxZg0aJFOH78OBYtWoSHHnoIBw4csNyFC8Sw+PDDDwUfH59ex3fs2CE4OTkJFy9elI598cUXglarFRoaGsy+Vn19veDq6ips3rxZOnbx4kXByclJ+OGHHyx+7SOhs7NTCAoKEl555ZV+z3v00UeFX/ziF7a5qBESGRkprFmzZtDn6/V6ITg4WPjb3/4mHWtvbxd8fHyEt99+2wpXaHn+/ve/C9HR0f2eI9fPcObMmcITTzxhdGzChAnCCy+8YPb8//mf/xEmTJhgdOy//uu/hMTERKtdoyWpqqoSAAh79uzp85xdu3YJAIS6ujrbXdgwefHFF4Vrr7120Ocr/fMTBEF49tlnhdjYWEGv15t9XEmfHwBh27Zt0t/DnQ8feugh4bbbbjM6duuttwoLFy602LWSB8fCZGdnY/LkyQgNDZWO3Xrrrejo6MDhw4fNPufw4cPo6urCvHnzpGOhoaGYPHkysrKyrH7NQ+Hbb79FdXU1HnvssQHP3b17N4KCghAfH48lS5agqqrK+hc4TF577TUEBATguuuuw6uvvtpv+KaoqAiVlZVGn5dWq8WcOXNk93n1RUNDA/z9/Qc8T26fYWdnJw4fPmz03gPAvHnz+nzvs7Oze51/66234tChQ+jq6rLatVqKhoYGABjU5zV16lSEhIQgJSUFu3btsvalDZv8/HyEhoYiOjoaCxcuRGFhYZ/nKv3z6+zsxKefforf/va3AzZ3VsrnxzPc+bCvz9WScygZOBamsrISY8eONTrm5+cHNzc3VFZW9vkcNzc3+Pn5GR0fO3Zsn8+xFxs3bsStt96K8PDwfs+bP38+PvvsM/z000/45z//idzcXNxyyy3o6Oiw0ZUOnmeffRabN2/Grl278PTTT2Pt2rV48skn+zyffSamn7McPy9zFBQU4PXXX8cTTzzR73ly/Ayrq6uh0+mG9N6b+06OHTsW3d3dqK6uttq1WgJBELBixQrccMMNmDx5cp/nhYSE4N1338XWrVvx9ddfY/z48UhJScHevXtteLWDY9asWfj444/x448/4r333kNlZSWSk5NRU1Nj9nwlf34A8M0336C+vr7fTaGSPj9Thjsf9vW5WnIOdchu4qa89NJLePnll/s9Jzc3d0DNCcOclS4IwoDWuyWeM1iGc8/l5eX48ccf8eWXXw74+gsWLJB+nzx5MqZPn47IyEhs374d99133/AvfJAM5f6WL18uHbvmmmvg5+eHBx54QPLq9IXpZ2PNz8scw/kML126hNtuuw0PPvggHn/88X6fa+/PsD+G+t6bO9/ccbnx9NNP48SJE9i/f3+/540fPx7jx4+X/k5KSkJZWRn+8Y9/4MYbb7T2ZQ6J+fPnS79PmTIFSUlJiI2NxUcffYQVK1aYfY5SPz9A3BTOnz/fyKtvipI+v74Yznxo7TmUDByIk8jChQv7PScqKmpQrxUcHNxLJFVXV4eurq5e1ir/nM7OTtTV1Rl5caqqqpCcnDyo/3eoDOeeP/zwQwQEBODuu+8e8v8XEhKCyMhI5OfnD/m5w2EknynLFLpw4YJZA4dlfFRWViIkJEQ6XlVV1ednbA2Geo+XLl3CzTffjKSkJLz77rtD/v9s/RmaIzAwEM7Ozr12ef2998HBwWbPd3Fx6deAtTfPPPMMvv32W+zduxdhYWFDfn5iYiI+/fRTK1yZZfHy8sKUKVP6HFdK/fwAoKSkBBkZGfj666+H/FylfH7DnQ/7+lwtOYeSgQNx0gwMDLTIayUlJeHVV19FRUWF9GHv3LkTWq0WCQkJZp+TkJAAV1dXpKen46GHHgIAVFRU4NSpU/j73/9ukesyZaj3LAgCPvzwQzzyyCNwdXUd8v9XU1ODsrIyoy+ANRnJZ3r06FEA6PNao6OjERwcjPT0dEydOhWAGGffs2cPXnvtteFd8DAYyj1evHgRN998MxISEvDhhx/CyWno0Wlbf4bmcHNzQ0JCAtLT03HvvfdKx9PT0/GLX/zC7HOSkpLw3XffGR3buXMnpk+fPqyxbG0EQcAzzzyDbdu2Yffu3YiOjh7W6xw9etSun9Vg6ejowNmzZzF79myzjyvt8+P58MMPERQUhDvuuGPIz1XK5zfc+TApKQnp6elGHvSdO3dadlNvMbmyg1BSUiIcPXpUePnll4VRo0YJR48eFY4ePSo0NTUJgiAI3d3dwuTJk4WUlBThyJEjQkZGhhAWFiY8/fTT0muUl5cL48ePFw4cOCAde+KJJ4SwsDAhIyNDOHLkiHDLLbcI1157rdDd3W3zezRHRkaGAEA4c+aM2cfHjx8vfP3114IgCEJTU5Pw3HPPCVlZWUJRUZGwa9cuISkpSbjqqquExsZGW172gGRlZQmrV68Wjh49KhQWFgpbtmwRQkNDhbvvvtvoPP7+BEEQ/va3vwk+Pj7C119/LZw8eVL45S9/KYSEhMju/gRBzMgbN26ccMsttwjl5eVCRUWF9MOjlM9w8+bNgqurq7Bx40bhzJkzwrJlywQvLy+huLhYEARBeOGFF4RFixZJ5xcWFgqenp7C8uXLhTNnzggbN24UXF1dhX/961/2uoV++d3vfif4+PgIu3fvNvqsWltbpXNM73HNmjXCtm3bhLy8POHUqVPCCy+8IAAQtm7dao9b6JfnnntO2L17t1BYWCjk5OQId955pzB69GjVfH4MnU4nRERECL///e97Paa0z6+pqUla6wBIc2ZJSYkgCIObDxctWmSU6fjzzz8Lzs7Owt/+9jfh7Nmzwt/+9jfBxcVFyMnJsdh1k4EzRB599FEBQK+fXbt2SeeUlJQId9xxh+Dh4SH4+/sLTz/9tNDe3i49XlRU1Os5bW1twtNPPy34+/sLHh4ewp133imUlpba8M7655e//KWQnJzc5+MAhA8//FAQBEFobW0V5s2bJ4wZM0ZwdXUVIiIihEcffVRW98M4fPiwMGvWLMHHx0dwd3cXxo8fL7z44otCS0uL0Xn8/QmCmBr54osvCsHBwYJWqxVuvPFG4eTJkza++sHx4Ycfmh2zpvsbJX2Gb775phAZGSm4ubkJ06ZNM0qhfvTRR4U5c+YYnb97925h6tSpgpubmxAVFSW89dZbNr7iwdPXZ8WPP9N7fO2114TY2FjB3d1d8PPzE2644QZh+/bttr/4QbBgwQIhJCREcHV1FUJDQ4X77rtPOH36tPS40j8/xo8//igAEM6fP9/rMaV9fiyN3fTn0UcfFQRhcPPhnDlzpPMZX331lTB+/HjB1dVVmDBhgsUNOo0gGNRaBEEQBEEQKoHSxAmCIAiCUB1k4BAEQRAEoTrIwCEIgiAIQnWQgUMQBEEQhOogA4cgCIIgCNVBBg5BEARBEKqDDByCIAiCIFQHGTgEQRAEQagOMnAIgiAIglAdZOAQBEEQBKE6yMAhCIIgCEJ1kIFDEARBEITq+P8obNTCtSbfZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Generate a sequence of numbers from -10 to 10 with 500 steps\n",
    "# Exercise 2.2\n",
    "y = np.linspace(-10,10,500)\n",
    "#Create a second array z as the cosine of y\n",
    "z = np.cos(y)\n",
    "#Use the plot function to plot array y against array z\n",
    "plt.plot(y,z,marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "#Create a simple dataset of people using Dictionary type\n",
    "# Exercise 2.3\n",
    "data = {'Name': [\"Segun\", \"Lawal\", \"Seyi\", \"Daniel\"], 'State': [\"Ogun\", \"Imo\", \"Delta\", \"Kwara\"], 'Age': [18, 20, 26, 28]}\n",
    "data_pandas = pd.DataFrame(data)\n",
    "#IPython.display allows fine printing of dataframes in Jupyter\n",
    "display(data_pandas)\n",
    "#Select all rows that have an age column less than or equal to 25\n",
    "display(data_pandas[data_pandas.Age<=25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420fbc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the required libraries\n",
    "# Exercise 2.4\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "## To get the list of available dataset, use tfds.list_builders()\n",
    "tfds.list_builders()\n",
    "##Load the dataset with tfds.load and convert the pandas.DataFrame with tfds.as_dataframe #to Visualise the dataset ds, \n",
    "info = tfds.load('mnist', split='train', shuffle_files=True, with_info=True)\n",
    "tfds.as_dataframe(ds.take(4), info)\n",
    "##tfds.show_examples returns a matplotlib.figure to show selected images \n",
    "##(Note that only image datasets are supported now)\n",
    "fig = tfds.show_examples(ds, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcee13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 3.1\n",
    "# example with the IRIS database\n",
    "#Import the required libraries\n",
    "import sklearn as sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the iris data to memory\n",
    "iris = load_iris()\n",
    "# The loaded iris is a dictionary - so check it\n",
    "iris.keys()\n",
    "# You can print the description of the dataset\n",
    "print(iris.DESCR)\n",
    "#Convert the loaded data and targets into a dataframe and print the first ten rows.\n",
    "X = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "#print(X.head())\n",
    "print(X.head(10))\n",
    "Y = pd.DataFrame(data=iris.target, columns = ['irisType'])\n",
    "print(Y.head(10))\n",
    "#Explore the number of classes in the target set\n",
    "Y.irisType.value_counts()\n",
    "#The names of the classes(i.e. species in the iris dataset)\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## April 20, 2023 classworks\n",
    "y = [0,0,0,0,0,1,1,1,1,1,2,2,2,2,2]\n",
    "_y = [0.4,0.7,0.3,0.5,0.7,1.2,0.8,0.1,0.4,0.6,1.8,1.2,2.1,0.9,2.0]\n",
    "yminus_y = []\n",
    "for i in range(15):\n",
    "    yminus_y.append(y[i] - _y[i])\n",
    "print(yminus_y)\n",
    "\n",
    "yminus_ysqr = []\n",
    "for i in yminus_y:\n",
    "    yminus_ysqr.append(i*i)\n",
    "    \n",
    "print(yminus_ysqr)\n",
    "    \n",
    "import numpy as np\n",
    "_sum = np.sum(yminus_ysqr)\n",
    "print(_sum)\n",
    "\n",
    "mse = _sum/15\n",
    "print(mse)\n",
    "\n",
    "import math\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(rmse)\n",
    "\n",
    "ayminus_y = []\n",
    "for i in range(15):\n",
    "    ayminus_y.append(abs(y[i] - _y[i]))\n",
    "print(yminus_y)\n",
    "\n",
    "yminus_ysqr = []\n",
    "for i in yminus_y:\n",
    "    yminus_ysqr.append(i*i)\n",
    "    \n",
    "print(yminus_ysqr)\n",
    "    \n",
    "import numpy as np\n",
    "_sum = np.sum(yminus_ysqr)\n",
    "print(_sum)\n",
    "\n",
    "mae = _sum/15\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1407652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "##Define y_true and y_pred for a regression task\n",
    "y_true = [1., 0.]\n",
    "y_pred = [2., 3.]\n",
    "#Compute and Print the MAE\n",
    "mae_loss = MeanAbsoluteError()\n",
    "print(\"The Mean Absolute Error is - \",mae_loss(y_true, y_pred).numpy())\n",
    "#Compute and Print the MSE\n",
    "mse_loss = MeanSquaredError()\n",
    "print(\"\")\n",
    "print(\"The Mean Square Error is - \",mse_loss(y_true, y_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6bf4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define y_true and y_pred for a classification task\n",
    "#Use one hot vector representation\n",
    "y_true = [[0, 1, 0], [1, 0, 0]]\n",
    "y_pred = [[0.15, 0.75, 0.1], [0.75, 0.15, 0.1]\n",
    "#Compute and print the categorical-cross-entropy-loss\n",
    "cross_entropy_loss = CategoricalCrossentropy()\n",
    "print(\"\")\n",
    "print(\"The Categorical Cross Entropy Loss is - \",cross_entropy_loss(y_true, y_pred).numpy())\n",
    "#Use label-encoded representation for the class\n",
    "y_true = [1, 0]\n",
    "y_pred = [[0.15, 0.75, 0.1], [0.75, 0.15, 0.1]]\n",
    "#Compute and print the sparse-cross-entropy-loss\n",
    "cross_entropy_loss = SparseCategoricalCrossentropy()\n",
    "print(\"\")\n",
    "print(\"The Sparse Categorical Cross Entropy Loss is - \"\n",
    ",cross_entropy_loss(y_true, \n",
    "y_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4114ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = numpy.random.uniform(0.0, 5.0, 100000)\n",
    "\n",
    "plt.hist(x, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb3887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18th may 2023, Artificial Neural Networks Practical\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "iris= load_iris()\n",
    "iris.keys()\n",
    "iris.target_names\n",
    "x = pd.DataFrame(data = iris.data[:100,:], columns = iris.feature_names)\n",
    "x.head(100)\n",
    "y = pd.DataFrame(data= iris.target[:100], columns = ['irisType'])\n",
    "y.head(100)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state =42)\n",
    "\n",
    "#display(x)\n",
    "#display(y)\n",
    "#display(x_train)\n",
    "\n",
    "mdPercept = Perceptron()\n",
    "mdPercept.fit(x_train, y_train)\n",
    "y_pred = mdPercept.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accurcacy:\", accuracy)\n",
    "print(\"Perceptron Confusion Matrix:\\n\", confusion_matrix(y_test,y_pred))\n",
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3236dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge class 2 ad 3 to make it one class, the it would be class 1 vs class 2x3\n",
    "\n",
    "x1 = pd.DataFrame(data = iris.data[:150,:], columns = iris.feature_names)\n",
    "x1.head(50)\n",
    "y1 = pd.DataFrame(data= iris.target[:150], columns = ['irisType'])\n",
    "y1.head(100)\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1,y1,test_size = 0.2, random_state =42)\n",
    "\n",
    "md1Percept = Perceptron()\n",
    "md1Percept.fit(x1_train, y1_train)\n",
    "y1_pred = md1Percept.predict(x1_test)\n",
    "accuracy1 = accuracy_score(y1_test, y1_pred)\n",
    "print(\"Accurcacy:\", accuracy1)\n",
    "print(\"Perceptron Confusion Matrix:\\n\", confusion_matrix(y1_test,y1_pred))\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78715437",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target']\n",
    "\n",
    "\n",
    "new_target = []\n",
    "\n",
    "for i in iris['target']:\n",
    "    if i == 0:\n",
    "        new_target.append(0)\n",
    "    else:\n",
    "        new_target.append(1)\n",
    "\n",
    "print(new_target)\n",
    "\n",
    "new_target_names = ['setosa', 'versicolor or virginica']\n",
    "new_target = numpy.array(new_target)\n",
    "new_target_names = numpy.array(new_target_names)\n",
    "X = pd.DataFrame(data = iris.data[:150,:], columns = iris.feature_names)\n",
    "y = new_target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size= 0.3, random_state=42)\n",
    "mdlPercept = Perceptron()\n",
    "mdlPercept.fit(X_train,y_train)\n",
    "y_pred = mdlPercept.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(acc)\n",
    "print(\"Perceptron Confusion Matrix:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2fb974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights from input to hidden layer:\n",
      "[[-1.14517604 -1.18781113  1.02583734 -1.84373096]\n",
      " [ 0.32782512  0.68200747 -0.12572704  0.04081536]\n",
      " [-2.12573494 -1.0910742   0.45962726 -1.31214498]]\n",
      "\n",
      "Weights from hidden to output layer:\n",
      "[[ 1.01458899  1.48717576]\n",
      " [ 0.63972352  0.66560697]\n",
      " [ 0.38914437  0.45499522]\n",
      " [-0.41082381 -1.74212371]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_inputs = 3\n",
    "num_hidden_layers = 1\n",
    "num_neurons = 4\n",
    "num_outputs = 2\n",
    "\n",
    "# Randomly initialize weights for the input layer to the hidden layer\n",
    "weights_input_hidden = np.random.randn(num_inputs, num_neurons)\n",
    "\n",
    "# Randomly initialize weights for the hidden layer to the output layer\n",
    "weights_hidden_output = np.random.randn(num_neurons, num_outputs)\n",
    "\n",
    "print(\"Weights from input to hidden layer:\")\n",
    "print(weights_input_hidden)\n",
    "print(\"\\nWeights from hidden to output layer:\")\n",
    "print(weights_hidden_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0b6a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.2627258075296389, 0.6146341714176651, 0.003311863217199784], [0.751205286046207, 0.5298667674397345, 0.8793471279996531], [0.9646084988112738, 0.773819597290885, 0.8757638846977982], [0.9937197858334686, 0.10894265955213323, 0.03693074422294862]], [[0.9665519315549237, 0.8690466161088009, 0.03398198487031978, 0.908899752894568], [0.32056778291033006, 0.9597451968702667, 0.2973456113715668, 0.460005362550193], [0.9367524293249833, 0.20191274954227323, 0.4882289908552736, 0.5327542112216388]], [[0.7074649033928344, 0.037380874720208124, 0.1261562726876101], [0.7594856808646355, 0.7869075102001398, 0.7048145372016731]]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "no_of_inputs = 3\n",
    "no_of_hidden_layers = 2\n",
    "no_of_neurons = [4, 3]\n",
    "no_of_outputs = 2\n",
    "weights = []\n",
    "\n",
    "for i in range(no_of_hidden_layers + 1):\n",
    "    # create an array for each layer except input\n",
    "    weights.append([])\n",
    "    \n",
    "    if i == 0:\n",
    "        no_of_neurons_current = no_of_inputs\n",
    "        no_of_neurons_next = no_of_neurons[0]\n",
    "    elif i == no_of_hidden_layers:\n",
    "        no_of_neurons_current = no_of_neurons[len(no_of_neurons) - 1]\n",
    "        no_of_neurons_next = no_of_outputs\n",
    "    else:\n",
    "        no_of_neurons_current = no_of_neurons[i - 1]\n",
    "        no_of_neurons_next = no_of_neurons[i]\n",
    "    \n",
    "    # create an array for each neuron in layer\n",
    "    for j in range(no_of_neurons_next):\n",
    "        weights[i].append([])\n",
    "        for k in range(no_of_neurons_current):\n",
    "            weights[i][j].append([])\n",
    "            weights[i][j][k] = random.random()\n",
    "            \n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75af8945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax output: [0.22734376 0.1684204  0.14496078 0.15239308 0.30688198]\n",
      "ReLU output: [1.2  0.9  0.75 0.8  1.5 ]\n",
      "Bipolar sigmoid output: [0.9168273  0.85814894 0.81757448 0.83201839 0.95257413]\n"
     ]
    }
   ],
   "source": [
    "# Assuming the weighted sum of five neurons is given as: [1.2, 0.9, 0.75, 0.8, 1.5]\n",
    "# use Python programming language with relevant framework to compute the\n",
    "# output of the neurons using the following activation functions:\n",
    "# i) Softmax\n",
    "# ii) ReLU\n",
    "# iii) Bipolar sigmoid with  = 1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the weighted sum of five neurons\n",
    "weighted_sum = np.array([1.2, 0.9, 0.75, 0.8, 1.5])\n",
    "\n",
    "# Define the activation functions\n",
    "def softmax(x):\n",
    "  return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def relu(x):\n",
    "  return np.maximum(0, x)\n",
    "\n",
    "def bipolar_sigmoid(x, q=1):\n",
    "  return (1 + np.tanh(q * x)) / 2\n",
    "\n",
    "# Calculate the output of the neurons using the three activation functions\n",
    "softmax_output = softmax(weighted_sum)\n",
    "relu_output = relu(weighted_sum)\n",
    "bipolar_sigmoid_output = bipolar_sigmoid(weighted_sum)\n",
    "\n",
    "# Print the output of the neurons\n",
    "print(\"Softmax output:\", softmax_output)\n",
    "print(\"ReLU output:\", relu_output)\n",
    "print(\"Bipolar sigmoid output:\", bipolar_sigmoid_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3074d1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear_data_home\n",
      "dump_svmlight_file\n",
      "fetch_20newsgroups\n",
      "fetch_20newsgroups_vectorized\n",
      "fetch_lfw_pairs\n",
      "fetch_lfw_people\n",
      "fetch_olivetti_faces\n",
      "fetch_species_distributions\n",
      "fetch_california_housing\n",
      "fetch_covtype\n",
      "fetch_rcv1\n",
      "fetch_kddcup99\n",
      "fetch_openml\n",
      "get_data_home\n",
      "load_diabetes\n",
      "load_digits\n",
      "load_files\n",
      "load_iris\n",
      "load_breast_cancer\n",
      "load_linnerud\n",
      "load_sample_image\n",
      "load_sample_images\n",
      "load_svmlight_file\n",
      "load_svmlight_files\n",
      "load_wine\n",
      "make_biclusters\n",
      "make_blobs\n",
      "make_circles\n",
      "make_classification\n",
      "make_checkerboard\n",
      "make_friedman1\n",
      "make_friedman2\n",
      "make_friedman3\n",
      "make_gaussian_quantiles\n",
      "make_hastie_10_2\n",
      "make_low_rank_matrix\n",
      "make_moons\n",
      "make_multilabel_classification\n",
      "make_regression\n",
      "make_s_curve\n",
      "make_sparse_coded_signal\n",
      "make_sparse_spd_matrix\n",
      "make_sparse_uncorrelated\n",
      "make_spd_matrix\n",
      "make_swiss_roll\n"
     ]
    }
   ],
   "source": [
    "#8th june, 2023\n",
    "#AI CLASS\n",
    "#ignore\n",
    "from sklearn import datasets as ds\n",
    "#Obtain the list of available datasets\n",
    "datasetList = ds.__all__\n",
    "#Print the dataset names\n",
    "for datasetName in datasetList:\n",
    "    print(datasetName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7932eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from svm textbook, chapter 2, codelisting 11-16\n",
    "\n",
    "#codelisting 11\n",
    "import numpy as np\n",
    "def perceptron_learning_algorithm(X, y):\n",
    "    w = np.random.rand(3) # can also be initialized at zero.\n",
    "    misclassified_examples = predict(hypothesis, X, y, w)\n",
    "    \n",
    "    while misclassified_examples.any():\n",
    "        x, expected_y = pick_one_from(misclassified_examples, X, y)\n",
    "        w = w + x * expected_y # update rule\n",
    "        misclassified_examples = predict(hypothesis, X, y, w)       \n",
    "    return w\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19d4a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codelisting 12\n",
    "def hypothesis(x, w):\n",
    "    return np.sign(np.dot(w, x))\n",
    "# Make predictions on all data points\n",
    "# and return the ones that are misclassified.\n",
    "def predict(hypothesis_function, X, y, w):\n",
    "    predictions = np.apply_along_axis(hypothesis_function, 1, X, w)\n",
    "    misclassified = X[y != predictions]\n",
    "    return misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e9f59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codelisting 13\n",
    "# Pick one misclassified example randomly\n",
    "# and return it with its expected label.\n",
    "def pick_one_from(misclassified_examples, X, y):\n",
    "    np.random.shuffle(misclassified_examples)\n",
    "    x = misclassified_examples[0]\n",
    "    index = np.where(np.all(X == x, axis=1))\n",
    "    return x, y[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73706e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-44.35244895   1.50714969   5.52834138]\n"
     ]
    }
   ],
   "source": [
    "#codelisting 14\n",
    "from succinctly.datasets import get_dataset, linearly_separable as ls\n",
    "np.random.seed(88)\n",
    "X, y = get_dataset(ls.get_training_examples)\n",
    "# transform X into an array of augmented vectors.\n",
    "X_augmented = np.c_[np.ones(X.shape[0]), X]\n",
    "w = perceptron_learning_algorithm(X_augmented, y)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bb458b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codelisting 15\n",
    "def update_rule(expected_y, w, x):\n",
    "    if expected_y == 1:\n",
    "        w = w + x\n",
    "    else:\n",
    "        w = w - x\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11d9cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codelisting 16\n",
    "def update_rule(expected_y, w, x): \n",
    "    w = w + x * expected_y\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13e28db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'breast_cancer.csv', 'data_module': 'sklearn.datasets.data'}\n"
     ]
    }
   ],
   "source": [
    "data = ds.load_breast_cancer()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f1f4379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data.keys()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c92e2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df = pd.DataFrame(data['data'], columns = data['feature_names'])\n",
    "cancer_df['Target'] = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ebc82c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  Target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e7e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main question:\n",
    "# Develop a classification model using the breast_cancer dataset in\n",
    "# Sklearn and the MLP Classifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_breast_cancer as ld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "039de3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 569\n",
      "Number of features: 30\n",
      "Target names: ['malignant' 'benign']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ld()\n",
    "data.keys()\n",
    "# Access the components of the dataset\n",
    "X = data.data           # Feature matrix (data)\n",
    "y = data.target         # Target variable\n",
    "feature_names = data.feature_names\n",
    "target_names = data.target_namesdata = ld()\n",
    "data.keys()\n",
    "# Access the components of the dataset\n",
    "X = data.data           # Feature matrix (data)\n",
    "y = data.target         # Target variable\n",
    "feature_names = data.feature_names\n",
    "target_names = data.target_names\n",
    "description = data.DESCR\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(\"Number of samples:\", X.shape[0])\n",
    "print(\"Number of features:\", X.shape[1])\n",
    "print(\"Target names:\", target_names)\n",
    "type(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80e928e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea66f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed60f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)# Create an MLP classifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', random_state=42)\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61cacda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e7770fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb88a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "print(data_cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "72a1f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_cancer['data'], columns = data_cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1425bb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2b4a23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target']= data_cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23a34436",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  Target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb1f5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb6adc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "775f8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5a12ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "541048ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data_cancer['data'], columns = data_cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2a77560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8bbed9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.14420</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "5          12.45         15.70           82.57      477.1          0.12780   \n",
       "6          18.25         19.98          119.60     1040.0          0.09463   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "5             0.17000         0.15780              0.08089         0.2087   \n",
       "6             0.10900         0.11270              0.07400         0.1794   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "5                   0.07613  ...          23.75           103.40       741.6   \n",
       "6                   0.05742  ...          27.66           153.20      1606.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "5             0.17910            0.52490           0.5355   \n",
       "6             0.14420            0.25760           0.3784   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  Target  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "5                  0.1741          0.3985                  0.12440       0  \n",
       "6                  0.1932          0.3063                  0.08368       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[567 rows x 31 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.drop(new_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3032f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4afba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(64,32),activation ='relu', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "827cefcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(64, 32), random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(64, 32), random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(64, 32), random_state=42)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c7c4d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf.score(X_test,y_test)\n",
    "print(accuracy)\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30442a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test,pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b50841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
